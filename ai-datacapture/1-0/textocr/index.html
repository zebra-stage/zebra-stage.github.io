
<!DOCTYPE html>
<html lang="en"><head>

    <meta charset="utf-8">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="-1">
    <meta http-equiv="CACHE-CONTROL" content="NO-CACHE">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Online Documentation for Zebra Technologies developer tools and utilties, including EMDK for Android, EMDK for Xamarin, StageNow and Enterprise Browser.">
    <meta name="author" content="Zebra Technologies">
    <meta name="google-site-verification" content="i4B78BrWnNy8ShJwe5feRW3jO3HE6gfYlYqYbxfl8yY">
    <meta name="msvalidate.01" content="6B651B00161BCE79B8950AC09D5C4C75">
    <meta title="Text OCR">
    <title>Text OCR - TechDocs</title>
    <!-- core CSS -->
    <link href="/css/bootstrap.min.css" rel="stylesheet">
<!--     
    <link href="/css/font-awesome.min.css" rel="stylesheet">
 -->    
    <link href="/css/all.css" rel="stylesheet">
    <link href="/css/v4-shims.css" rel="stylesheet">
    <link href="/css/animate.min.css" rel="stylesheet">
    <link href="/css/owl.carousel.css" rel="stylesheet">
    <link href="/css/owl.transitions.css" rel="stylesheet">
    <link href="/css/prettyPhoto.css" rel="stylesheet">
    <link href="/css/main.css" rel="stylesheet">
    <link href="/css/responsive.css" rel="stylesheet">
    <link href="/css/prettify.css" rel="stylesheet">
    <link href="/css/bootstrap-treenav.min.css" rel="stylesheet">
    <!--[if lt IE 9]>
    <script src="js/html5shiv.js"></script>
    <script src="js/respond.min.js"></script>
    <![endif]--> 

    <!-- 6/13/24- a "crown" icon randomly appeared in the MX matrix today. Rob said it looked like sumo. 
        <script src="//load.sumome.com/" data-sumo-site-id="699cb66cf4dc59352efb45705526d15cbe314e1cd43f7761b94d96f3cf7338e8" async="async"></script> -->
    <link rel="shortcut icon" href="/favicon.ico">
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-01QJCMQM9N"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-01QJCMQM9N');
</script><script src="/js/jquery.js"></script></head><!--/head-->

<!-- Google tag -->





<body id="home" class="homepage" data-spy="scroll" data-offset="100" data-target="#toc">

    <header id="header">
        <nav id="main-menu" class="navbar navbar-default navbar-fixed-top" role="banner">
            <div class="container-fluid">
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="/"><img src="/images/logo.png" alt="logo" style="max-height:66px;float: inherit;
    padding-right: 3px;"></a> 
                    
                   
                </div>
                <div class="collapse navbar-collapse navbar-left">
                    <ul class="nav navbar-nav">
                        <li class="navbar-text pull-left"><strong>TechDocs</strong></li>
                        <p class="navbar-text">
                                            AI Data Capture SDK
                                            1.0
                        </p>

                    </ul>
                </div>
                <div class="collapse navbar-collapse navbar-right">
                    <ul class="nav navbar-nav">
                        


                        <li>
                            <a href="/ai-datacapture/1-0/about">
                                    About
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/localizer">
                                    Localizer
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/productrecognition">
                                    Product Recognition
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/barcodedecoder">
                                    Barcode Decoder
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/textocr">
                                    Text OCR
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/samples">
                                    Samples
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/search">
                                    <i class="fa fa-search"></i>
                            </a>
                        </li>
                        
                        <!-- <li ><a href="/products">SDKs</a></li>
                        <li ><a href="/samples">Samples</a></li>
                        <li ><a href="/guides">Guides</a></li>
                        <li ><a href="/tutorials">Tutorials</a></li>
                        <li ><a href="/apis">APIs</a></li> -->
                        <!-- <li><a href="#"><input type="text" class="st-default-search-input"></a></li> -->
                    </ul>
                </div>
            </div><!--/.container-->
        </nav><!--/nav-->
    </header><!--/header-->
<div class="container-fluid">
    <section id="blog">
        <div class="">
            <section class="content-with-sidebar">
            <div class="row">
                <div class="col-sm-3 hidden-sm hidden-xs" id="sidebar">
                    
                    
                    <nav id="toc" data-toggle="toc" data-spy="affix" style="height: 75%; max-width: 225px; overflow-y: auto; ">
                        
                        <ul class="nav">
                            <li><strong>Text OCR</strong></li>
                        </ul>
                    </nav>
                    <div class="modal fade" id="modal-smartdocs" tabindex="-1" role="dialog" aria-labelledby="basicModal" aria-hidden="true" data-backdrop="true">
                    	<div class="modal-dialog">
                    		<div class="modal-content">
                    			<div class="modal-header">
                    				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">X</button>
                    			</div>
                    			<div class="modal-body">
                    				<form>
                    				  <div class="form-group">
                    				    <label for="exampleInputEmail1">MX Version On Device:</label>
                    				    <select class="form-control">
                    					  <option value="4.0">4.0</option>
                    					  <option value="4.1">4.1</option>
                    					  <option value="4.2">4.2</option>
                    					  <option value="4.3">4.3</option>
                    					  <option value="5.0">5.0</option>
                    					</select>
                    				  </div>						
                    				  <div class="form-group">
                    				    <label for="exampleInputEmail1">OSX Version On Device:</label>
                    				    <select class="form-control">
                    					  <option value="1.0">1.0</option>
                    					  <option value="1.2">1.2</option>
                    					  <option value="1.3.4-56">1.3.4-56</option>
                    					  <option value="3.4">3.4</option>
                    					  <option value="3.5">3.5</option>
                    					  <option value="3.6">3.6</option>
                    					  <option value="4.1">4.1</option>
                    					  <option value="4.2">4.2</option>
                    					  <option value="4.3">4.3</option>
                    					  <option value="4.4">4.4</option>
                    					</select>
                    				  </div>						
                    				  <div class="form-group">
                    				    <label for="exampleInputEmail1">Android Version On Device:</label>
                    				    <select class="form-control">
                    					  <option value="23">6.0 Marshmallow</option>
                    					  <option value="22">5.1 Lollipop</option>
                    					  <option value="21">5.0 Lollipop</option>
                    					  <option value="19">4.4 Kitkat</option>
                    					  <option value="18">4.3 Jellybean</option>
                    					  <option value="17">4.2.x Jellybean</option>
                    					  <option value="16">4.1.x Jellybean</option>
                    					  <option value="15">4.0.3-4.0.4 Ice Cream Sandwich</option>
                    					  <option value="14">4.0-4.0.2 Ice Cream Sandwich</option>
                    					  <option value="10">2.3.3-2.3.4 Gingerbread</option>
                    					</select>
                    				  </div>
                    				  <div class="form-group">
                    				  	<button class="primary" id="btn_SaveSmartDocOptions">Save Changes</button><button class="primary" id="btn_ClearSmartDocOptions">Clear Changes</button>
                    				  </div>
                    				</form>
                    			</div>
                    	</div>
                      </div>
                    </div>
                    
                    <script type="text/javascript">
                        $(document).ready(function() {
                        	$( "#btn_SaveSmartDocOptions" ).click(function() {
                      			console.log('Saving Options');
                      			$("#modal-smartdocs").modal({show: false});
                    		});
                        	$( "#btn_SaveSmartDocOptions" ).click(function() {
                      			console.log('Clearing Options');
                      			$("#modal-smartdocs").modal({show: false});
                    		});
                        });
                    </script><link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v0.3.0/dist/bootstrap-toc.min.css">
                    <script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v0.3.0/dist/bootstrap-toc.min.js"></script>
                    <script type="text/javascript">
                        $(document).ready(function() {
                    
                        });
                    
                    
                    </script>
                </div>                
                <div class="col-sm-9 ">
                    <div class="row">
                        <div class="col-sm-12">
                            <section id="cta" class="wow fadeIn">
                                <div class="">
                                    <h1 id="text-ocr" class="anchor"><a class="heading-anchor" href="#text-ocr"><span></span></a>Text OCR</h1>
                                    <p>
                                            AI Data Capture SDK
                                            1.0
                                    </p>
                                </div>
                            </section>                    
                        </div>
                    </div>
                    <div id="mainContent" class="row">
                        <div class="col-sm-12">
                            <div class="blog-post blog-large wow fadeInLeft" data-wow-duration="300ms" data-wow-delay="0ms">
                            <!-- Start of guide -->
                                <div class="service-box wow fadeInRight">
                                    <div class="">

                                        <p></p><h2 id="overview" class="anchor"><a class="heading-anchor" href="#overview"><span></span></a>Overview</h2>

<p>The <code>TextOCR</code> class uses Optical Character Recognition (OCR) to detect and recognize text within images. It offers methods for identifying text, words, and paragraphs in various image formats, with customizable output options, such as grouping detected words into "lines" or "paragraphs." </p>

<p><strong>Text OCR</strong> operates through a two-stage process:  </p>

<ol>
<li><strong>Detection Stage -</strong> Processes the input image to produce <a href="../class/bbox/">bounding boxes</a>, or text boxes, which are rotated rectangles not necessarily perpendicular to the image’s edges. </li>

<li><strong>Recognition Stage -</strong> Analyzes each text box to generate a list of possible text decodes. </li>
</ol>

<p>Although these stages are streamlined for the end user, developers can fine-tune them using parameters outlined in this guide.</p>

<p>The initial instructions in this guide provide the basic setup of TextOCR. A comprehensive list of OCR settings, along with their effects on detection and recognition, is provided in the subsequent sections. For atypical use cases, developers are encouraged to experiment with and adjust these parameters. </p><p style="color:red;">UPDATE NEEDED</p><p></p>

<hr>

<h2 id="capabilities" class="anchor"><a class="heading-anchor" href="#capabilities"><span></span></a>Capabilities</h2>

<h3 id="supportedcharacters" class="anchor"><a class="heading-anchor" href="#supportedcharacters"><span></span></a>Supported Characters</h3>

<p>TextOCR recognizes a range of characters, including:</p>

<pre class="prettyprint"><code>    *0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&amp;'()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~*
</code></pre>

<p>By default, it supports a maximum word length of approximately 15 characters, though this limit may decrease with the use of uncommon fonts. Enabling <a href="../textocr/#tilingoptions">tiling</a> removes this restriction.</p>

<h3 id="inputoutput" class="anchor"><a class="heading-anchor" href="#inputoutput"><span></span></a>Input/Output</h3>

<p><strong>Input Parameters:</strong> The default model input size is 640x640 pixels, but this can be adjusted during runtime initialization. 
<strong>Output Parameters:</strong> The output consists of a list of text detections, each accompanied by a list of <a href="../class/bbox/">bounding boxes</a> that define the location and content of the detected text.</p>

<hr>

<h2 id="developerguide" class="anchor"><a class="heading-anchor" href="#developerguide"><span></span></a>Developer Guide</h2>

<h3 id="step1initialization" class="anchor"><a class="heading-anchor" href="#step1initialization"><span></span></a>Step 1: Initialization</h3>

<p>Set up and initialize a TextOCR object:</p>

<ol>
<li><p><strong>Import the TextOCR class</strong> using <code>com.zebra.ai.vision.TextOCR</code>.</p></li>

<li><p><strong>Configure OCR Settings:</strong> </p>

<p></p><ul>
<li>Set <code>model_file_path</code> with the fully qualified file path to the .crypt file containing the OCR model. </li></ul><p></p>

<p></p></li><li>Create a <code>TextOCR.Settings</code> object with the specified file path.</li><p></p>

<li><p><strong>Optional: Set model input dimensions:</strong> If needed, customize the model input dimensions (height and width). These should be multiples of 32 (e.g., 640). </p>

<pre class="prettyprint"><code>settings.detectionInferencerOptions.defaultDims.width = [your value];
settings.detectionInferencerOptions.defaultDims.height = [your value];
</code></pre>

<ul>
<li><strong>Smaller Input Sizes -</strong> Reduce processing time and increase speed, but may decrease accuracy. Ideal for larger or closer text.</li>

<li><strong>Larger Input Sizes -</strong> Improve accuracy for smaller or more distant text, but increase inference time. An input size that is too large may cause out-of-memory errors and potentially cause an application crash at run-time.</li></ul></li>

<li><p><strong>Initialize the OCR object -</strong> Declare a <code>TextOCR</code> object. Use <code>CompletableFuture</code> to initialize it asynchronously with an <code>Executor</code> for concurrent processing.</p></li>

<li><p><strong>Callback Handling -</strong> Use <code>thenAccept()</code> to assign the initialized <code>TextOCR</code> object to the <code>textocr</code> variable, enabling it for text detection tasks like barcodes and products in images.</p></li>
</ol>

<p>For more advanced inferencer options, refer to <a href="#inferenceroptions">Inferencer Options</a>. </p>

<h4 id="samplecode" class="anchor"><a class="heading-anchor" href="#samplecode"><span></span></a>Sample Code</h4>

<pre class="prettyprint"><code>    import com.zebra.ai.vision.TextOCR;

    TextOCR.Settings settings = new TextOCR.Settings(model_file_path);

    // Optional: Override the default model input size
    settings.detectionInferencerOptions.defaultDims.width = 640;
    settings.detectionInferencerOptions.defaultDims.height = 480;

    // Initialize OCR object
    TextOCR textocr = null;

    // Initialize textocr
    // settings = TextOCR.Settings object created above
    // Executor = An executor thread for processing API calls and returning results
    CompletableFuture&lt;TextOCR&gt; futureObject = getTextOCR(settings, executor);

    // Use the futureObject to implement the thenAccept() callback of CompletableFuture
    futureObject.thenAccept (OCRInstance -&gt; { 
        // Use the Textocr object returned here for detecting barcodes/Shelves/products 
        textocr = OCRInstance; 
    });
</code></pre>

<h3 id="step2captureimage" class="anchor"><a class="heading-anchor" href="#step2captureimage"><span></span></a>Step 2: Capture Image</h3>

<p>Capture the image and ensure the image is in the form of a Bitmap.</p>

<h3 id="step3detecttext" class="anchor"><a class="heading-anchor" href="#step3detecttext"><span></span></a>Step 3: Detect Text</h3>

<p>Use one of the following methods to detect text within an image, based on generic text, words or paragraphs:</p>

<ul>
<li><p style="color:red;">UPDATE NEEDED</p></li>

<li><strong><a href="#detectwords">DetectWords</a> –</strong> Outputs an array of words. A word is a discrete unit of text identified within an image, typically separated by spaces or punctuation.</li>

<li><strong><a href="#detectparagraphs">DetectParagraphs</a> -</strong>  Outputs a hierarchical structure of paragraphs. It employs a grouping mechanism as outlined in the <a href="#ADD LINK">Grouper Settings</a>. A paragraph consists of a collection of words, where words on the same line are grouped together. These lines are further organized into paragraphs. The entire process is parameterized, with relevant parameters detailed in the Grouper Settings.</li>
</ul>

<p style="color:red;">UPDATE NEEDED - LINK</p>

<h4 id="samplecode-1" class="anchor"><a class="heading-anchor" href="#samplecode-1"><span></span></a>Sample Code</h4>

<p>To detect generic text:</p>

<pre class="prettyprint"><code>    Bitmap image = ... // Your bitmap image here       

    // Initialize executor 
    Executor executor = Executors.newFixedThreadPool(1); 

    // Input parameters include a bitmap image and an executor thread object for performing detections
    CompletableFuture&lt;OCRResult[]&gt; futureResult = textocr.detect(bitmap,executor);  

    futureResult.thenAccept (ocrResults -&gt; {    
        // Process the returned output that contains bounding boxes and text within
    }); 

    // Once finished with the textOCR object, dispose of it to release resources and memory used during detection. 
    textOCR.dispose(); 
</code></pre>

<p>To detect words:</p>

<pre class="prettyprint"><code>    Bitmap image = ... // Your bitmap image here 

    // Initialize executor 
    Executor executor = Executors.newFixedThreadPool(1); 

    // Input parameters include a bitmap image and an executor thread object for performing detections
    CompletableFuture&lt;Word[]&gt; futureWords = textocr.detectWords(bitmap,executor); 

    futureWords.thenAccept (words -&gt; {   
        // Process the returned array of detected words   
    }); 

    // Once finished with the textOCR object, dispose of it to release resources and memory used during detection
    textOCR.dispose(); 
</code></pre>

<p>To detect paragraphs:</p>

<pre class="prettyprint"><code>    Bitmap image = ... // Your bitmap image here 

    // Initialize executor 
    Executor executor = Executors.newFixedThreadPool(1); 

    // Input parameters include a bitmap image and an executor thread object for performing detection
    CompletableFuture&lt;TextParagraph[]&gt; futureTextParagraph = textOCR.detectParagraphs(bitmap,executor); 

    futureTextParagraph.thenAccept (paragraphs -&gt; {   
        // Process the returned array of detected paragraphs.   
    }); 

    // Once finished with the textOCR object, dispose of it to release resources and memory used during detection
    textOCR.dispose(); 
</code></pre>

<hr>

<h2 id="apis" class="anchor"><a class="heading-anchor" href="#apis"><span></span></a>APIs</h2>

<h3 id="textocrsettingssettings" class="anchor"><a class="heading-anchor" href="#textocrsettingssettings"><span></span></a>TextOCR (Settings settings)</h3>

<pre class="prettyprint"><code>    TextOCR.TextOCR(Settings settings) throws IOException 
</code></pre>

<p><strong>Description:</strong> Initializes the OCR engine with the specified settings, allowing subsequent text detection and analysis on image inputs. It checks for the necessary model file and verifies the integrity of the archive. If issues are detected, appropriate exceptions are thrown. </p>

<p><strong>Parameters:</strong></p>

<ul>
<li><strong>settings TextOCR.Settings -</strong> An instance of the <code>Settings</code> class containing configuration options for the OCR engine, such as model path, language preferences, and performance settings. </li>
</ul>

<p><strong>Return Value:</strong> <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html">CompletableFuture</a>&lt;TextOCR&gt; </p>

<p><strong>Exceptions:</strong></p>

<ul>
<li><strong>IOException -</strong> Thrown if the archive is corrupted. </li>
</ul>

<hr>

<h3 id="detectbitmapsrcimgexecutorexecutor" class="anchor"><a class="heading-anchor" href="#detectbitmapsrcimgexecutorexecutor"><span></span></a>detect (Bitmap srcImg, Executor executor)</h3>

<pre class="prettyprint"><code>    CompletableFuture&lt;OCRResult[]&gt; detect (Bitmap srcImg, Executor executor) throws InvalidInputException, IllegalStateException 
</code></pre>

<p><strong>Description:</strong> Performs Optical Character Recognition (OCR) on the provided Bitmap image, using the specified executor for asynchronous execution. </p>

<p><strong>Parameters:</strong> </p>

<ul>
<li><strong>srcImg (Bitmap srcImg) -</strong> The Bitmap image to perform OCR on. </li>

<li><strong>executor -</strong> Manages asynchronous task execution. </li>
</ul>

<p><strong>Return Value:</strong> A <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html">CompletableFuture</a> that resolves to an array of <code>OCRResult</code>, each containing <a href="../class/bbox/">bounding boxes</a> and recognized text. </p>

<p><strong>Exceptions:</strong></p>

<ul>
<li><strong>InvalidInputException -</strong> Thrown if the Bitmap is null. </li>

<li><strong>IllegalStateException -</strong> Thrown if the OCR engine is in an invalid state for detection. </li>
</ul>

<hr>

<h3 id="detectwordsbitmapsrcimgexecutorexecutor" class="anchor"><a class="heading-anchor" href="#detectwordsbitmapsrcimgexecutorexecutor"><span></span></a>detectWords (Bitmap srcImg, Executor executor)</h3>

<pre class="prettyprint"><code>    CompletableFuture&lt;Word[]&gt; TextOCR.detectWords (Bitmap srcImg, Executor executor) throws InvalidInputException, IllegalStateException 
</code></pre>

<p><strong>Description:</strong> Detects individual words in the provided Bitmap image using the specified executor for asynchronous execution. </p>

<p><strong>Parameters:</strong></p>

<ul>
<li><strong>srcImg (Bitmap srcImg) -</strong> The image to analyze for word detection. </li>

<li><strong>Executor -</strong> Manages asynchronous task execution. </li>
</ul>

<p><strong>Return Value:</strong> A <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html">CompletableFuture</a> that resolves to an array of Word objects, each containing <a href="../class/bbox/">bounding boxes</a> and possible text decodes. </p>

<p><strong>Exceptions:</strong></p>

<ul>
<li><strong>InvalidInputException -</strong> Thrown if the Bitmap is null. </li>

<li><strong>IllegalStateException -</strong> Thrown if the OCR engine is in an invalid state for performing word detection. </li>
</ul>

<hr>

<h3 id="detectparagraphsbitmapsrcimgexecutorexecutor" class="anchor"><a class="heading-anchor" href="#detectparagraphsbitmapsrcimgexecutorexecutor"><span></span></a>detectParagraphs (Bitmap srcImg, Executor executor)</h3>

<pre class="prettyprint"><code>    CompletableFuture&lt;TextParagraph[]&gt; detectParagraphs(Bitmap srcImg, Executor executor) 
</code></pre>

<p><strong>Description:</strong> Detects paragraphs in the provided Bitmap image using the specified executor for asynchronous execution. </p>

<p><strong>Parameters:</strong></p>

<ul>
<li><strong>srcImg (Bitmap srcImg) -</strong> The image to analyze for paragraph detection. </li>

<li><strong>executor -</strong> Manages asynchronous task execution. </li>
</ul>

<p><strong>Return Value:</strong> A <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html">CompletableFuture</a> that resolves to an array of TextParagraph objects, representing detected paragraphs. </p>

<p><strong>Exceptions:</strong></p>

<ul>
<li><strong>InvalidInputException -</strong> Thrown if the Bitmap is null. </li>

<li><strong>IllegalStateException -</strong> Thrown if the OCR engine is in an invalid state for performing paragraph detection. </li>
</ul>

<hr>

<h3 id="gettextocrsettingssettingsexecutorexecutor" class="anchor"><a class="heading-anchor" href="#gettextocrsettingssettingsexecutorexecutor"><span></span></a>getTextOCR (Settings settings, Executor executor)</h3>

<pre class="prettyprint"><code>    CompletableFuture&lt;TextOCR&gt; getTextOCR(Settings settings, Executor executor) 
</code></pre>

<p><strong>Description:</strong> Asynchronously initializes and retrieves a TextOCR instance using the specified settings and executor. </p>

<p><strong>Parameters:</strong></p>

<ul>
<li><strong>Settings -</strong> An instance of <code>TextOCR.Settings</code> containing configuration options for the OCR engine. </li>

<li><strong>executor -</strong> Manages asynchronous task execution. </li>
</ul>

<p><strong>Return Value:</strong> A <a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html">CompletableFuture</a> that resolves to an initialized TextOCR instance. </p>

<p><strong>Exceptions:</strong></p>

<ul>
<li><strong>InvalidInputException -</strong> Thrown if the settings are invalid or null. </li>

<li><strong>RuntimeException -</strong> Thrown if an unexpected error occurs during initialization. </li>
</ul>

<hr>

<h3 id="dispose" class="anchor"><a class="heading-anchor" href="#dispose"><span></span></a>Dispose()</h3>

<pre class="prettyprint"><code>    void dispose() 
</code></pre>

<p><strong>Description:</strong> Releases all internal resources used by the TextOCR object. This function must be called manually to free up resources. </p>

<hr>

<h2 id="textocrsettings" class="anchor"><a class="heading-anchor" href="#textocrsettings"><span></span></a>TextOCR.Settings</h2>

<p>The <code>Settings</code> class is a nested class within the <code>TextOCR</code> class, designed to configure various parameters required for performing Optical Character Recognition (OCR). It allows for fine-tuning of the OCR process through settings related to detection, recognition, and decoding. </p>

<hr>

<h2 id="constructors" class="anchor"><a class="heading-anchor" href="#constructors"><span></span></a>Constructors</h2>

<h3 id="settings" class="anchor"><a class="heading-anchor" href="#settings"><span></span></a>Settings()</h3>

<pre class="prettyprint"><code>    TextOCR.Settings settings = new TextOCR.Settings();
</code></pre>

<p><strong>Description:</strong> Constructs a new <code>Settings</code> object with default values for all parameters.</p>

<hr>

<h3 id="settingsstringresource_filename" class="anchor"><a class="heading-anchor" href="#settingsstringresource_filename"><span></span></a>Settings(String resource_filename)</h3>

<pre class="prettyprint"><code>    TextOCR.Settings settings = new TextOCR.Settings(String resource_filename);
</code></pre>

<p><strong>Description:</strong> Constructs a new <code>Settings</code> object with a specified resource file path.</p>

<p><strong>Parameters:</strong></p>

<ul>
<li><strong>resource_filename -</strong> The path to the resource file containing the OCR model.</li>
</ul>

<hr>

<h3 id="settingsstringresource_filenamestringdetector_model_namestringrecognition_model_name" class="anchor"><a class="heading-anchor" href="#settingsstringresource_filenamestringdetector_model_namestringrecognition_model_name"><span></span></a>Settings(String resource_filename, String detector_model_name, String recognition_model_name)</h3>

<pre class="prettyprint"><code>    TextOCR.Settings settings = new TextOCR.Settings(String resource_filename, String detector_model_name, String recognition_model_name);
</code></pre>

<p><strong>Description:</strong> Constructs a new <code>Settings</code> object with a specified resource file, detector model name, and recognition model name.</p>

<p><strong>Parameters:</strong></p>

<ul>
<li><strong>resource_filename -</strong> Path to the resource file containing the OCR model.</li>

<li><strong>detector_model_name -</strong> Name of the detector model in the archive file.</li>

<li><strong>recognition_model_name -</strong> Name of the recognition model in the archive file.</li>
</ul>

<hr>

<h2 id="recognitionparametersettings" class="anchor"><a class="heading-anchor" href="#recognitionparametersettings"><span></span></a>Recognition Parameter Settings</h2>

<h3 id="decodingmaxwordcombinations" class="anchor"><a class="heading-anchor" href="#decodingmaxwordcombinations"><span></span></a>decodingMaxWordCombinations</h3>

<pre class="prettyprint"><code>    int TextOCR.Settings.decodingMaxWordCombinations
</code></pre>

<p><strong>Description:</strong> Specifies the maximum number of possible text decodes returned in the output. This parameter helps balance the quantity and confidence of text outputs. It is applicable for the following scenarios:</p>

<ul>
<li><strong>Detailed Text Analysis -</strong> Increase this parameter for applications that require a thorough analysis of text.</li>

<li><strong>Data Extraction -</strong> Adjust this parameter to optimize the extraction of comprehensive data from documents with complex or ambiguous text.</li>
</ul>

<p><strong>Tuning effect:</strong> Increasing this number returns more decodes, but potentially with lower confidence.</p>

<p><strong>Default:</strong> 10</p>

<p><strong>Valid range:</strong> [1, max(int)]</p>

<hr>

<h3 id="decodingtotalprobthreshold" class="anchor"><a class="heading-anchor" href="#decodingtotalprobthreshold"><span></span></a>decodingTotalProbThreshold</h3>

<pre class="prettyprint"><code>    float TextOCR.Settings.decodingTotalProbThreshold
</code></pre>

<p><strong>Description:</strong> Sets the minimum cumulative confidence score required for character decodes to be considered valid. This is crucial in the Total decoding strategy of the OCR recognition process, balancing accuracy and coverage in text recognition. If this threshold is not reached, no high-confidence decode exists, and a placeholder (�) appears in the output.</p><p style="color:red;">UPDATE NEEDED - char</p> This parameter is relevant in the following scenarios:<p></p>

<ul>
<li><strong>Improving Decode Coverage -</strong> Lower the threshold in scenarios where critical text characters are missing to capture more potential decodes.</li>

<li><strong>Complex Document Analysis -</strong> Apply this setting in documents with ambiguous or low-quality text to ensure more comprehensive character recognition.</li>

<li><strong>Adaptive Recognition -</strong> Adjust dynamically based on the quality and complexity of input documents to optimize OCR performance for specific needs.</li>
</ul>

<p><strong>Tuning effect:</strong> Lowering this value may help if many characters are not decoded (indicated by multiple � characters), . </p>

<p style="color:red;">UPDATE NEEDED - char</p>

<p><strong>Default:</strong> 0.9f</p>

<p><strong>Valid range:</strong> [0.0f, 1.0f]</p>

<hr>

<h3 id="decodingtopkignorecutoff" class="anchor"><a class="heading-anchor" href="#decodingtopkignorecutoff"><span></span></a>decodingTopkIgnoreCutoff</h3>

<pre class="prettyprint"><code>    int TextOCR.Settings.decodingTopkIgnoreCutoff
</code></pre>

<p><strong>Description:</strong> Sets the maximum number of decodes considered for each character before calculating the cumulative probability, impacting the accuracy and completeness of text recognition. It is used specifically within the Total decoding strategy of the OCR recognition process. This parameter is applicable for the following scenarios:</p>

<ul>
<li><strong>Complex Text Recognition -</strong> Increase this parameter for documents with complex or ambiguous text where capturing all character variations is crucial.</li>

<li><strong>Improving Character Accuracy -</strong> Use this setting in scenarios where critical text components are consistently missing, ensuring thorough character analysis.</li>

<li><strong>Adaptive Text Processing -</strong> Adjust dynamically based on the complexity and quality of input text to optimize OCR performance.</li>
</ul>

<p><strong>Tuning effect:</strong> Generally, keep this at the default value. If the expected character does not appear in the OCR output, increasing this value allows for more less confident decodes.</p>

<p><strong>Default:</strong> 4</p>

<p><strong>Valid range:</strong> [1, max(int)]</p>

<hr>

<h3 id="samplecode-2" class="anchor"><a class="heading-anchor" href="#samplecode-2"><span></span></a>Sample Code</h3>

<p>Sample code demonstrating use of Recognition Parameters:</p>

<ol>
<li><p><strong>Initialize Settings:</strong> Configure the OCR settings, including the model path and additional parameters such as <code>heatmapThreshold</code> and <code>tiling</code>.</p></li>

<li><p><strong>Create TextOCR Instance:</strong> Use an executor to initialize the <code>TextOCR</code> instance asynchronously with the configured settings.</p></li>

<li><p><strong>Load Bitmap Image:</strong> Prepare the bitmap image that you want to analyze using OCR.</p></li>

<li><p><strong>Perform OCR:</strong> Invoke the <code>detect</code> method on the <code>TextOCR</code> instance to analyze the bitmap image, managing the asynchronous processing with the executor.</p></li>

<li><p><strong>Process OCR Results:</strong> Handle the results, which include bounding boxes and recognized text.</p></li>

<li><p><strong>Dispose Resources:</strong> After completing OCR operations, call the <code>dispose</code> method on the <code>TextOCR</code> instance to release resources and prevent memory leaks.</p>

<pre class="prettyprint"><code>import com.zebra.ai.vision.TextOCR;
import com.zebra.ai.vision.TextOCR.Settings;
import android.graphics.Bitmap;

// Initialize settings 
TextOCR.Settings textOCRSettings = new TextOCR.Settings ("path_to_model/text_ocr_snpe_tar.crypt");            
textOCRSettings.heatmapThreshold = 0.5f;
textOCRSettings.decodingTotalProbThreshold = 0.9f;
textOCRSettings.tiling.enable = true;

// Instantiate TextOCR with the configured settings
// settings = TextOCR.Settings object created above 
// Executor = An executor thread for processing API calls and returning results

// Initialize executor
Executor executor = Executors.newFixedThreadPool(1);

CompletableFuture&lt;TextOCR&gt; futureObject = getTextOCR(textOCRSettings, executor);

// Use the futureObject to implement thenAccept() callback of CompletableFuture.  
futureObject.thenAccept (OCRInstance -&gt; {  
    // Use the textocr object returned here detecting barcodes, shelves, or products  
    textocr = OCRInstance;  
});

// Load your Bitmap image
Bitmap image = ...; 

// Perform OCR
CompletableFuture&lt;OCRResult[]&gt; futureResult = textocr.detect(bitmap,executor);  
futureResult.thenAccept (ocrResults -&gt; {    
    // Process the returned output that contains bounding boxes and recognized text
});

// Dispose resources
// Once done using the textOCR object, dispose it to release resources and memory used for detection.  
textOCR.dispose()
</code></pre></li>
</ol>

<hr>

<h2 id="detectionparametersettings" class="anchor"><a class="heading-anchor" href="#detectionparametersettings"><span></span></a>Detection Parameter Settings</h2>

<h3 id="detectionmodelname" class="anchor"><a class="heading-anchor" href="#detectionmodelname"><span></span></a>detectionModelName</h3>

<pre class="prettyprint"><code>    TextOCR.Settings.detectionModelName
</code></pre>

<p><strong>Description:</strong> Name of the detector model within the OCR resource archive.</p>

<hr>

<h3 id="flip" class="anchor"><a class="heading-anchor" href="#flip"><span></span></a>flip</h3>

<pre class="prettyprint"><code>    boolean TextOCR.Settings.flip
</code></pre>

<p><strong>Description:</strong> If set to true, performs recognition twice - once in the regular orientation and once rotated by 180 degrees.</p>

<hr>

<h3 id="recognitionmodelname" class="anchor"><a class="heading-anchor" href="#recognitionmodelname"><span></span></a>recognitionModelName</h3>

<pre class="prettyprint"><code>    TextOCR.Settings.recognitionModelName
</code></pre>

<p><strong>Description:</strong> Name of the recognition model within the OCR resource archive.</p>

<hr>

<h3 id="resourcename" class="anchor"><a class="heading-anchor" href="#resourcename"><span></span></a>resourceName</h3>

<pre class="prettyprint"><code>    TextOCR.Settings.resourceName
</code></pre>

<p><strong>Description:</strong> File path to the OCR resources, including models.</p>

<hr>

<h3 id="detectioninferenceroptions" class="anchor"><a class="heading-anchor" href="#detectioninferenceroptions"><span></span></a>detectionInferencerOptions</h3>

<pre class="prettyprint"><code>    InferencerOptions TextOCR.Settings.detectionInferencerOptions = new InferencerOptions()
</code></pre>

<p><strong>Description:</strong> Allows developers to specify a different input shape for the detection stage inferencer.</p>

<hr>

<h3 id="recognitioninferenceroptions" class="anchor"><a class="heading-anchor" href="#recognitioninferenceroptions"><span></span></a>recognitionInferencerOptions</h3>

<pre class="prettyprint"><code>    InferencerOptions TextOCR.Settings.recognitionInferencerOptions = new InferencerOptions()
</code></pre>

<p><strong>Description:</strong> Typically remains unchanged as the input size is fixed for the recognition model. Developers can adjust recognition results using parameters in the Recognition Options section. TensorRT users might use the caching mechanism available here.
<strong>Note:</strong> These options should not be changed by the developer. </p><p style="color:red;">UPDATE NEEDED: Recognition Options? TensorRT?</p><p></p>

<hr>

<h3 id="heatmapthreshold" class="anchor"><a class="heading-anchor" href="#heatmapthreshold"><span></span></a>heatmapThreshold</h3>

<pre class="prettyprint"><code>    float TextOCR.Settings.heatmapThreshold
</code></pre>

<p><strong>Description:</strong> Internally, the detector model creates a grayscale image (heatmap) that represents text confidence. This parameter sets a cutoff to identify potential areas likely to contain text, converting them into text boxes.</p>

<p><strong>Tuning effect:</strong></p>

<ul>
<li><strong>Increase Threshold -</strong> Reduces areas identified as text, useful for high-contrast images like scanned documents.</li>

<li><strong>Decrease Threshold -</strong> Expands areas identified as text, useful for low-contrast or barely visible text.</li>
</ul>

<p><strong>Default:</strong> 0.5f</p>

<p><strong>Valid range:</strong> [0.0f, 1.0f]</p>

<hr>

<h3 id="minboxarea" class="anchor"><a class="heading-anchor" href="#minboxarea"><span></span></a>minBoxArea</h3>

<pre class="prettyprint"><code>    int TextOCR.Settings.minBoxArea
</code></pre>

<p><strong>Description:</strong> Filters out small, unimportant boxes from the OCR output.</p>

<p><strong>Tuning effect:</strong> Increasing this parameter filters out boxes with small areas.</p>

<p><strong>Default:</strong> 10
<strong>Valid range:</strong> [0, max(int)]</p>

<hr>

<h3 id="boxthreshold" class="anchor"><a class="heading-anchor" href="#boxthreshold"><span></span></a>boxThreshold</h3>

<pre class="prettyprint"><code>    float TextOCR.Settings.boxThreshold
</code></pre>

<p><strong>Description:</strong> Sets the minimum confidence score required for a text box to be included in the OCR output. Boxes with confidence scores below this threshold are excluded, helping to filter out less certain text detections.</p>

<p><strong>Tuning effect:</strong></p>

<ul>
<li><strong>Increase Threshold:</strong> Excludes less-confident text boxes, useful when too many boxes are detected.</li>

<li><strong>Decrease Threshold:</strong> Includes more text boxes, which might be necessary when important text is being missed.</li>
</ul>

<p><strong>Default:</strong> 0.85f</p>

<p><strong>Valid range:</strong> [0, 1.0]</p>

<hr>

<h3 id="minboxsize" class="anchor"><a class="heading-anchor" href="#minboxsize"><span></span></a>minBoxSize</h3>

<pre class="prettyprint"><code>    int TextOCR.Settings.minBoxSize
</code></pre>

<p><strong>Description:</strong> Filters out very narrow boxes (low height or width) that likely do not contain real text.</p>

<p><strong>Tuning effect:</strong> Increasing this parameter filters out very narrow boxes.</p>

<p><strong>Default:</strong> 1</p>

<p><strong>Valid range:</strong> [0, max(int)]</p>

<hr>

<h3 id="minratioforrotation" class="anchor"><a class="heading-anchor" href="#minratioforrotation"><span></span></a>minRatioForRotation</h3>

<pre class="prettyprint"><code>    float TextOCR.Settings.minRatioForRotation
</code></pre>

<p><strong>Description:</strong> Rotates vertically oriented text boxes to horizontal to improve recognition. Adjust this value for images with significant rotated text. <strong>Note:</strong> Words are generally wider than they are tall, so their ratio should exceed the default value. Therefore, avoid changing this parameter for words, since word bounding boxes should be horizontally oriented before recognition.</p>

<p><strong>Tuning effect:</strong> Setting this parameter to 0 disables rotation. Otherwise, rotate boxes with a height-to-width ratio exceeding this value 90 degrees counterclockwise before recognition.</p>

<p><strong>Default:</strong> 1.5f</p>

<p><strong>Valid range:</strong> [0.0f, inf]</p>

<hr>

<h3 id="unclipratio" class="anchor"><a class="heading-anchor" href="#unclipratio"><span></span></a>unclipRatio</h3>

<pre class="prettyprint"><code>    float TextOCR.Settings.unclipRatio
</code></pre>

<p><strong>Description:</strong> Slightly stretches text boxes before recognition to improve results. Tight-fitting boxes might benefit from some extra background for better decoding.</p>

<p><strong>Tuning effect:</strong> Increasing this parameter enlarges text boxes, potentially improving recognition. An unclipRatio of 1 keeps boxes unchanged, while 1.5 enlarges them by 50%.</p>

<p><strong>Default:</strong> 1.5f</p>

<p><strong>Valid range:</strong> [1.0f, inf]</p>

<hr>

<h3 id="samplecode-3" class="anchor"><a class="heading-anchor" href="#samplecode-3"><span></span></a>Sample Code</h3>

<p>This sample code demonstrates how to adjust detection parameter settings:</p>

<ol>
<li><p><strong>Configure Settings:</strong> Set up the OCR model and adjust parameters such as <code>heatmapThreshold</code> and <code>boxThreshold</code> to improve detection accuracy based on your specific needs.</p></li>

<li><p><strong>Instantiate TextOCR:</strong> Create a <code>TextOCR</code> object using the settings. This object will handle text detection and recognition tasks.</p></li>

<li><p><strong>Load Bitmap Image:</strong> Prepare the image you want to process by converting it to a Bitmap object.</p></li>

<li><p><strong>Detect Text:</strong> Call the <code>detect</code> method to analyze the image and retrieve an array of <code>OCRResult</code> objects containing the detected text.</p></li>

<li><p><strong>Print Results:</strong> Iterate over the <code>OCRResult</code> array to output the recognized text to the console.</p></li>

<li><p><strong>Dispose Resources:</strong> Free up system resources by calling the <code>dispose</code> method on the <code>TextOCR</code> object after usage.</p>

<pre class="prettyprint"><code>import com.zebra.ai.vision.TextOCR;
import com.zebra.ai.vision.TextOCR.Settings;
import android.graphics.Bitmap;

// Initialize settings with a custom heatmap threshold
TextOCR.Settings textOCRSettings = new TextOCR.Settings ("path_to_model/text_ocr_snpe_tar.crypt");
settings.heatmapThreshold = 0.3f; // Lower threshold for low-contrast text
settings.boxThreshold = 0.9f; // Higher threshold for more confident text boxes
settings.minBoxSize = 10; // Set minimum box size to 10 pixels
settings.minBoxArea = 50; // Set minimum box area to 50 pixels
settings.resizeDetectorToImage = true; // Enable full-resolution processing
settings.unclipRatio = 2.0f; // Enlarge text boxes by 100%
settings.minRatioForRotation = 2.0f; // Rotate boxes with height-to-width ratio exceeding 2.0

// Initialize executor
Executor executor = Executors.newFixedThreadPool(1);

CompletableFuture&lt;TextOCR&gt; futureObject = getTextOCR(textOCRSettings, executor);

// Use the futureObject to implement thenAccept() callback of CompletableFuture.  
futureObject.thenAccept (OCRInstance -&gt; {  
    // Use the Textocr object returned here for the detection of barcodes/shelves/products  
    textocr = OCRInstance;  
});

// Load your Bitmap image
Bitmap image = ...; // This is your input image

// Perform OCR
CompletableFuture&lt;OCRResult[]&gt; futureResult = textocr.detect(bitmap,executor);  
futureResult.thenAccept (ocrResults -&gt; {    
    // Process the returned output that contains bounding boxes and recognized text    
});

// Dispose resources
// Once done using the textOCR object, dispose of it to release resources and memory used for detection
textOCR.dispose();
</code></pre></li>
</ol>

<hr>

<!-- 
---

## Usage

Detect text in an image, outputting words or paragraphs. A paragraph is a collection of words with additional hierarchical structure, where words on the same line are grouped into lines, and lines into paragraphs. This process is parameterized, with relevant parameters described in [Options](#options).

Sample API calls to retrieve both words and paragraphs:

        CompletableFuture<Word[]> words = textocr.detectWords(IMAGE); // com.zebra.AI.Vision.Word[]
        CompletableFuture<TextParagraph[]> paragraphs = textocr.detectParagraphs(IMAGE); // com.zebra.AI.Vision.TextParagraph[]

`IMAGE` represents the bitmap image.

### Definitions

Definitions for key terms:
* **Bounding box -** A list of points forming a rectangle, which may not be perpendicular to the bottom and sides of the screen. More than 4 points can be present if the rectangle is clipped at the edges of the screen. Each bounding box includes:
    - **Coordinates of the bounding rectangle -** Defines the position and size of the detected object.
    - **Probability (Confidence) -** Indicates the certainty of the detection.
    - **Class -** Specifies the type of object detected.
* **Paragraph -** Contains a complex bounding box and an array of lines.
* **Line -** Contains a complex bounding box and an array of words.
* **Word -** Contains a complex bounding box and an array of decodes.
* **Decode -** Contains decoded text strings (referred to as content) and their confidence.

## Options

The `Options` structure provides configuration settings for the `TextOCR` library, containing a detection and recognition stage. These settings customize OCR behavior.

### Model Configuration

1. **modelFileLocator**
   - **Description**: Location of the file containing resources for the models and meta values.
   - **Type**: `FileLocator`
2. **detectionModelName**
   - **Description**: Name of the detection model in the compressed file.
   - **Type**: `string`
   - **Default**: `"det"`
3. **recognitionModelName**
   - **Description**: Name of the recognition model in the compressed file.
   - **Type**: `string`
   - **Default**: `"rec"`

### Inferencer Options
Advanced options for inferencer can be found in [inferencer options](../class/inferenceroptions/).

1. **recognitionInferencerOptions**
   - **Description**: Options for the recognition inferencer.
   - **Type**: [`Inferencer::Options`](../class/inferenceroptions/)
2. **detectionInferencerOptions**
   - **Description**: Options for the detection inferencer. The same as for recognition inferencer.
   - **Type**: [`Inferencer::Options`](../class/inferenceroptions/)

### Detection Parameters

1. **heatmapThreshold**
   - **Description**: Threshold for detector model output heatmap. The detector model's output is a grayscale image of [0, 1.0] real values, representing the confidence that a given pixel contains text. Raising this threshold value results in fewer areas being classified as text.
   - **Type**: `float`
   - **Default**: `0.5f`
2. **boxThreshold**
   - **Description**: Minimum confidence for a box from heatmap. After thresholding, the resulting bounding boxes are filtered based on their confidence. Raising this parameter will result in fewer bounding boxes being used by OCR.
   - **Type**: `float`
   - **Default**: `0.85f`
3. **minBoxSize**
   - **Description**: Minimum size of box side from heatmap. Raising this parameter will filter out the boxes with small width or height.
   - **Type**: `int`
   - **Default**: `1`
4. **minBoxArea**
   - **Description**: Minimum area of box from heatmap. Raising this parameter will filter out boxes with small area.
   - **Type**: `int`
   - **Default**: `10`
5. **resizeDetectorToImage**
    - **Description**: Indicates whether to use dynamic detector resolution. Setting this to true will result in the detector being resized to match the input data, not the other way around. This way, even large images can be processed without loss of information.
    - **Type**: `bool`
    - **Default**: `false` for SNPE models and `true` for onnx and openvino models.
    - **Example**: If the input image is 1024x1024 and `resizeDetectorToImage` is true, the detector will resize to 1024x1024. If false, the image will resize to the detector's default size.
6. **unclipRatio**
    - **Description**: A factor of unclipping bounding boxes before the recognition stage. Before doing the OCR, a border is added at the edges of each bounding box to provide better recognition results. Raising this parameter will increase this border and can result in better recognition.
    - **Type**: `float`
    - **Default**: `1.5f`
7. **minRatioForRotation**
    - **Description**: Minimum ratio of height to width for the word crop to rotate. If `0`, no rotation will be performed. Otherwise, the boxes with a height to width ratio higher than this value will be rotated 90 degrees (counterclockwise) before recognition.
    - **Type**: `float`
    - **Default**: `1.5f`

### Decoding Options

1. **decoderType**
    - **Description**: Recognition stage decoding strategy. The OCR algorithm works at the character level. For each character in an image, it predicts multiple characters and their confidences. The decoding strategy decides which of those predictions to choose for each character. Words are created by combining the chosen predictions. All the words along with their corresponding confidences are provided as output.
    - **Type**: `OcrDecoderType` (see below)
    - **Default**: `OcrDecoderType::Total`
2. **OcrDecoderType**
    - **Description**: Types of decoding strategies available.
    - **Enum Values**:
      - `Cutoff`: Use cutoff decoding strategy. The characters with confidence below a threshold are ignored. This decoding strategy produces only one output.
      - `TopK`: Use TopK decoding strategy. The decoding is done by considering the top-k predictions for each character and then calculating all possible combinations of the characters along with their joint probabilities.
      - `Total`: Use total decoding strategy. The decoding is done by considering the characters with cumulative probability greater than a threshold. The characters with cumulative probability below the threshold are ignored. Then, all possible combinations of the characters along with their joint probabilities are calculated.
3. **decodingCharacterConfidenceThreshold**
    - **Description**: Confidence threshold for single characters (for Cutoff and TopK decodings only). The characters with confidence below a threshold are ignored. Raising the threshold will pick only characters with high confidence. It returns an empty string if it can't find any above the threshold.
    - **Type**: `float`
    - **Default**: `0.9f`
4. **decodingMaxWordCombinations**
    - **Description**: The maximum number of possible word outcomes returned in the output. Increasing the number will consider less confident words.
    - **Type**: `int`
    - **Default**: `10`
5. **decodingTopKCharacters**
    - **Description**: The number of characters to consider for TopK decoding. Increasing the number will consider less confident characters.
    - **Type**: `int`
    - **Default**: `3`
6. **decodingTopkIgnoreCutoff**
    - **Description**: The maximum number of characters to consider for total decoding. Increasing the value will increase the number of decodes considered for each character.
    - **Type**: `int`
    - **Default**: `4`
7. **decodingTotalProbThreshold**
    - **Description**: The minimum cumulative sum score of characters required for total decoding. If this threshold is not reached, all characters will be ignored. Increasing the threshold will consider only characters with high cumulative probability.
    - **Type**: `float`
    - **Default**: `0.9f`

<br />

### Grouping Options
Grouping works in two stages. Words detected by OCR are grouped into lines that are further grouped into paragraphs as shown in the schema below. Words, lines and paragraphs in the graphics below are represented by blue, green and fuchsia colored borders respectively.

<img alt="image" style="height:300px"  src="../about/assets/schema.png" />
<!-- ![schema](../about/assets/schema.png) -->

<ul>
<li><p><strong>Description</strong>: A structure containing parameters for the word into line and line into paragraph grouping.</p></li>

<li><p><strong>Type</strong>: <code>TextOCRGrouper::Options</code></p></li>

<li><p><strong>Fields</strong>:</p>

<ol>
<li><p><strong>widthDistanceRatio</strong></p>

<ul>
<li><strong>Description</strong>: Determines whether the distance between the centers of two words along the x-axis is significantly large. Raising this parameter will cause words that are spaced out horizontally to be joined into a line.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>1.5f</code></li>

<li><strong>Example</strong>: If the average width of words is 90 pixels, setting <code>widthDistanceRatio</code> to 2.0 will allow words up to 180 pixels apart to be grouped into the same line.</li></ul>

<p><img alt="image" style="height:75px" src="../about/assets/widthDistanceRatio.jpg"></p></li>

<li><p><strong>heightDistanceRatio</strong></p>

<ul>
<li><strong>Description</strong>: Determines whether there is a significant difference in the height of two words. Raising this parameter will cause words of different heights to be joined into a line.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>2.0f</code></li>

<li><strong>Example</strong>: <code>heightDistanceRatio</code> to 4.0 will allow words with heights in the range of from approximately 0.25 and 4 times the height to be grouped into the same line.</li></ul>

<p><img alt="image" style="height:75px" src="../about/assets/heightDistanceRatio.jpg"></p></li>

<li><p><strong>centerDistanceRatio</strong></p>

<ul>
<li><strong>Description</strong>: Determines whether the distance between the centers of two boxes along the y-axis is significantly large. Raising this parameter will cause words that are not strictly aligned in a straight line to be joined into a line object.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.6f</code></li>

<li><strong>Example</strong>: If the average height of words is 20 pixels, setting <code>centerDistanceRatio</code> to 1.0 will allow words with centers up to 20 pixels apart vertically to be grouped into the same line.</li></ul>

<p><img alt="image" style="height:75px" src="../about/assets/centerDistanceRatio.jpg"></p></li>

<li><p><strong>paragraphHeightDistance</strong></p>

<ul>
<li><strong>Description</strong>: Determines the difference in the distance between the centers of two rows along the y-axis. Raising this parameter will cause lines that are spaced out vertically to be joined into a paragraph.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>1.0f</code></li>

<li><strong>Example</strong>: If the average height of lines is 30 pixels, setting <code>paragraphHeightDistance</code> to 2 will allow lines with centers up to 60 pixels apart vertically to be grouped into the same paragraph.</li></ul>

<p><img alt="image" style="height:125px" src="../about/assets/paragraphHeightDistance.jpg"></p></li>

<li><p><strong>paragraphHeightRatioThreshold</strong></p>

<ul>
<li><strong>Description</strong>: Determines whether there is a significant difference in the heights of two rows. Lowering this parameter will cause lines with higher difference in heights to be joined into a paragraph.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>1.0f/3.0f</code></li>

<li><strong>Example</strong>: If the average height of lines is 50 pixels, setting <code>paragraphHeightRatioThreshold</code> to 0.2 will allow lines with heights ranging from approximately 10 pixels to 250 pixels to be grouped into the same paragraph.</li></ul>

<p><img alt="image" style="height:125px" src="../about/assets/paragraphHeightRatioThreshold.jpg"></p></li></ol></li>
</ul>

<h3 id="tilingoptions" class="anchor"><a class="heading-anchor" href="#tilingoptions"><span></span></a>Tiling Options</h3>

<ul>
<li><strong>Description</strong>: A structure containing parameters related to handling very long text boxes.</li>

<li><strong>Type</strong>: <code>OpenCVOcrTiler::Options</code></li>

<li><strong>Fields</strong>:


<ol>
<li><strong>enable</strong>


<ul>
<li><strong>Description</strong>: Enable tiling of elongated text boxes. Boxes that match aspect ratio criteria will be split into multiple images (tiles) and recognition will be performed on each of them. After that, a correlation method will be used to merge the results of recognition into a single set of decodes. Enabling this option may help recognize text in long strings of characters.</li>

<li><strong>Type</strong>: <code>bool</code></li>

<li><strong>Default</strong>: <code>false</code></li></ul>
</li>

<li><strong>topCorrelationThr</strong>


<ul>
<li><strong>Description</strong>: Increasing this value will reduce the number of combinations used internally to perform tiling based on their confidence. Tuning this value may increase/decrease tiling result accuracy. Setting it to 0 will turn this feature off.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.0f</code></li>

<li><strong>Valid range</strong>: <code>[0.0f, 1.0f]</code></li></ul>
</li>

<li><strong>mergePointsCutoff</strong>


<ul>
<li><strong>Description</strong>: This is an internal parameter used to limit the number of possible combinations used for tile merging. Raising this value will result in more combinations being used internally and will increase the processing time but can also generate more accurate results.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>5</code></li></ul>
</li>

<li><strong>splitMarginFactor</strong>


<ul>
<li><strong>Description</strong>: This parameter scales the confidence values for characters that are at the borders of consecutive tiles, assuming that characters that these characters could be deformed due to cutting the image into tiles. It's not recommended to modify this value.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.1f</code></li>

<li><strong>Valid range</strong>: <code>[0.0f, 1.0f]</code></li></ul>
</li>

<li><strong>aspectRatioLowerThr</strong>


<ul>
<li><strong>Description</strong>: Tiling algorithm decides which boxes should be tiled and which not. Lowering this threshold will result with more boxes, with smaller aspect ratio (width/height) being tiled. Lowering this value can result in increased processing time.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>10.0f</code></li></ul>
</li>

<li><strong>aspectRatioUpperThr</strong>


<ul>
<li><strong>Description</strong>: This threshold alows filtering of boxes with very high aspect ratio. Such boxes rarely occur naturally and sometimes are a false positive of text detector model. Lowering this value will result in less boxes being tiled.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>40.0f</code></li></ul>
</li>

<li><strong>topkMergedPredictions</strong>


<ul>
<li><strong>Description</strong>: The final tiling result - the decodes, are sorted based on their confidence score. This setting allows the user to limit the number of decodes being returned from the OCR.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>5</code></li></ul>
</li></ol>
</li>
</ul>

<p><br></p>

<h2 id="apis-1" class="anchor"><a class="heading-anchor" href="#apis-1"><span></span></a>APIs</h2>

<p>The <code>TextOCR</code> class is part of the <code>com.zebra.AI.Vision</code> package and is used for detecting and recognizing text in images. It provides methods for detecting text at different granularities, including words and paragraphs. This class is essential for applications that require text extraction from images, such as document scanning, automated data entry, and more.</p>

<h3 id="textocrsettingssettings-1" class="anchor"><a class="heading-anchor" href="#textocrsettingssettings-1"><span></span></a>TextOCR(Settings settings)</h3>

<p>Initializes the OCR engine with the specified settings, allowing subsequent text detection and analysis on image inputs. It validates the availability of required model files and ensures the integrity of the archive. If any issues are detected, appropriate exceptions are thrown.</p>

<ul>
<li><strong>Constructor:</strong>


<ul>
<li>TextOCR.TextOCR (<a href="../textocr/textocrsettings/">Settings</a> settings) throws FileNotFoundException, IOException</li></ul>
</li>

<li><strong>Parameters:</strong>


<ul>
<li><code>settings</code> - <a href="../textocr/textocrsettings/">TextOCR.Settings settings</a> to construct an OCR object with.
An instance of the <code>Settings</code> class, containing configuration options for the OCR engine. These settings include model paths, language preferences, and performance configurations.</li></ul>
</li>

<li><strong>Exceptions:</strong>


<ul>
<li><code>FileNotFoundException</code> - Thrown if the required model file is not found in the archive.</li>

<li><code>IOException</code> - Thrown if the archive is corrupted.</li></ul>
</li>
</ul>

<h3 id="detectbitmapsrcimg" class="anchor"><a class="heading-anchor" href="#detectbitmapsrcimg"><span></span></a>detect (Bitmap srcImg)</h3>

<p>Performs Optical Character Recognition (OCR) on the provided Bitmap image.</p>

<ul>
<li><strong>Method:</strong>


<ul>
<li><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html">CompletableFuture</a>&lt;<a href="../class/ocrresult/">OCRResult</a>[ ]&gt; TextOCR.detect (Bitmap srcImg) throws <a href="../class/invalidinputexception/">InvalidInputException</a></li></ul>
</li>

<li><strong>Parameters:</strong>


<ul>
<li><code>srcImg</code> (Bitmap srcImg) - A <code>Bitmap</code> image to perform OCR detection on.</li></ul>
</li>

<li><strong>Return Value:</strong>


<ul>
<li>An array of <a href="../class/ocrresult/">OCRResult</a> containing bounding boxes and recognized text.</li></ul>
</li>

<li><strong>Exceptions:</strong>


<ul>
<li><code>InvalidInputException</code> - Thrown when Bitmap is passed as null. </li></ul>
</li>
</ul>

<h3 id="detectwordsbitmapsrcimg" class="anchor"><a class="heading-anchor" href="#detectwordsbitmapsrcimg"><span></span></a>detectWords(Bitmap    srcImg)</h3>

<p>Detects individual words in the given Bitmap image. Each word may have multiple possible readings with associated confidence scores.</p>

<ul>
<li><strong>Method:</strong> 


<ul>
<li><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html">CompletableFuture</a>&lt;<a href="../class/word/">Word</a>[ ]&gt; TextOCR.detectWords(Bitmap    srcImg) throws <a href="../class/invalidinputexception/">InvalidInputException</a></li></ul>
</li>

<li><strong>Parameters:</strong>


<ul>
<li><code>srcImg</code> (Bitmap srcImg) - The image to analyze for word detection.</li></ul>
</li>

<li><strong>Exceptions:</strong>


<ul>
<li><code>InvalidInputException</code> thrown when Bitmap is passed as null. </li></ul>
</li>

<li><strong>Return Value:</strong>


<ul>
<li>An array of <code>Words</code> objects containing bounding boxes and possible text decodes.</li></ul>
</li>
</ul>

<h3 id="detectparagraphsbitmapsrcimg" class="anchor"><a class="heading-anchor" href="#detectparagraphsbitmapsrcimg"><span></span></a>detectParagraphs (Bitmap    srcImg)</h3>

<p>Detects paragraphs in the given Bitmap image. Words are grouped into lines and paragraphs based on layout.</p>

<ul>
<li><strong>Prototype:</strong>


<ul>
<li><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html">CompletableFuture</a>&lt;<a href="../class/textparagraph/">TextParagraph</a>[ ]&gt; TextOCR.detectParagraphs (Bitmap    srcImg) throws <a href="../class/invalidinputexception/">InvalidInputException</a></li></ul>
</li>

<li><strong>Parameters:</strong>


<ul>
<li><code>srcImg</code> (Bitmap srcImg): The image to analyze for paragraph detection.</li></ul>
</li>

<li><strong>Return Value:</strong>


<ul>
<li>An array of <code>TextParagraph</code> objects representing detected paragraphs.</li></ul>
</li>

<li><strong>Exceptions:</strong> 


<ul>
<li><code>InvalidInputException</code> - Thrown when Bitmap is passed as null. </li></ul>
</li>
</ul>

<h3 id="dispose-1" class="anchor"><a class="heading-anchor" href="#dispose-1"><span></span></a>dispose ()</h3>

<p>Releases all internal resources used by the <code>TextOCR</code> object. This function needs to be called manually to free up resources.</p>

<ul>
<li><strong>Constructor:</strong>


<ul>
<li>void dispose()</li></ul>
</li>
</ul>

<p>--&gt;</p><p></p>
                                        


                                    </div>
                                </div>

                            </div>
                        </div>
                    </div>
                </div><!--/.col-sm-6-->
            </div>
            </section>
        </div>
    </section>    

<div class="modal fade" id="basicModal" tabindex="-1" role="dialog" aria-labelledby="basicModal" aria-hidden="true" data-backdrop="true">
			<div class="modal-dialog">
				<div class="modal-content">
					<div class="modal-header">
						<button type="button" class="close" data-dismiss="modal" aria-hidden="true">X</button>
					</div>
					<div class="modal-body">
						<div id="modalImg">
						
						</div>
					</div>
			</div>
		  </div>
		</div> </div>
         <footer id="footer">
            <div class="container-fluid">
                <div class="row">
                    <div class="col-sm-10">
                        ZEBRA and the stylized Zebra head are trademarks of Zebra Technologies Corp., registered in many jurisdictions worldwide. All other trademarks are the property of their respective owners. ©2025 Zebra Technologies Corp. and/or its affiliates.<br> <a href="https://www.zebra.com/us/en/about-zebra/company-information/legal.html">Legal</a> | <a href="https://www.zebra.com/us/en/about-zebra/company-information/compliance/information-privacy/terms-of-use.html">Terms of Use</a> | <a href="https://www.zebra.com/us/en/about-zebra/company-information/legal/privacy-statement.html">Privacy Policy</a> 
                    </div>
                     <!--
                     <div class="col-sm-2">
                        <ul class="social-icons">
                            <li><a href="http://www.facebook.com/pages/Zebra-Technologies/107703715989073"><i class="fa fa-facebook"></i></a></li>
                            <li><a href="https://twitter.com/ZebraDevs"><i class="fa fa-twitter"></i></a></li>
                            <li><a href="http://www.youtube.com/zebratechnologies/"><i class="fa fa-youtube"></i></a></li>
                            <li><a href="https://www.linkedin.com/groups?home=&gid=3220074&trk=anet_ug_hm&goback=%2Egmr_3220074"><i class="fa fa-linkedin"></i></a></li>
                            <li><a href="https://github.com/developer-zebra"><i class="fa fa-github"></i></a></li>
                        </ul>
                    </div> -->
                 </div>
            </div>
        </footer>
    
    <!--/#footer 
        10/25/18 removed <footer id="footer" class="navbar-fixed-bottom">
    -->
    <script src="/js/bootstrap.min.js"></script>
    <script src="/js/owl.carousel.min.js"></script>
    <script src="/js/mousescroll.js"></script>
    <script src="/js/smoothscroll.js"></script>
    <script src="/js/jquery.prettyPhoto.js"></script>
    <script src="/js/jquery.isotope.min.js"></script>
    <script src="/js/jquery.inview.min.js"></script>
    <script src="/js/wow.min.js"></script>
    <script src="/js/bootstrap-treenav.min.js"></script>
    <script src="/js/prettify.js"></script>
    <script src="/js/zepto.js"></script>
    <script src="/js/jquery.waterfall.js"></script>   
    <script src="/js/main.js"></script>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install','zRzEsAUhWTTkrdEN2YfA','2.0.0');
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-72584442-1', 'auto');
  ga('send', 'pageview');

</script> 

<script>
    ChatraID = 'QDvZ76min4DhLW5vJ';
    (function(d, w, c) {
        var n = d.getElementsByTagName('script')[0],
            s = d.createElement('script');
        w[c] = w[c] || function() {
            (w[c].q = w[c].q || []).push(arguments);
        };
        s.async = true;
        s.src = (d.location.protocol === 'https:' ? 'https:': 'http:')
            + '//call.chatra.io/chatra.js';
        n.parentNode.insertBefore(s, n);
    })(document, window, 'Chatra');
</script>         


</body></html>