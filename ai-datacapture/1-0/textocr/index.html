
<!DOCTYPE html>
<html lang="en"><head>

    <meta charset="utf-8">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="-1">
    <meta http-equiv="CACHE-CONTROL" content="NO-CACHE">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Online Documentation for Zebra Technologies developer tools and utilties, including EMDK for Android, EMDK for Xamarin, StageNow and Enterprise Browser.">
    <meta name="author" content="Zebra Technologies">
    <meta name="google-site-verification" content="i4B78BrWnNy8ShJwe5feRW3jO3HE6gfYlYqYbxfl8yY">
    <meta name="msvalidate.01" content="6B651B00161BCE79B8950AC09D5C4C75">
    <meta title="Text OCR">
    <title>Text OCR - TechDocs</title>
    <!-- core CSS -->
    <link href="/css/bootstrap.min.css" rel="stylesheet">
<!--     
    <link href="/css/font-awesome.min.css" rel="stylesheet">
 -->    
    <link href="/css/all.css" rel="stylesheet">
    <link href="/css/v4-shims.css" rel="stylesheet">
    <link href="/css/animate.min.css" rel="stylesheet">
    <link href="/css/owl.carousel.css" rel="stylesheet">
    <link href="/css/owl.transitions.css" rel="stylesheet">
    <link href="/css/prettyPhoto.css" rel="stylesheet">
    <link href="/css/main.css" rel="stylesheet">
    <link href="/css/responsive.css" rel="stylesheet">
    <link href="/css/prettify.css" rel="stylesheet">
    <link href="/css/bootstrap-treenav.min.css" rel="stylesheet">
    <!--[if lt IE 9]>
    <script src="js/html5shiv.js"></script>
    <script src="js/respond.min.js"></script>
    <![endif]--> 

    <!-- 6/13/24- a "crown" icon randomly appeared in the MX matrix today. Rob said it looked like sumo. 
        <script src="//load.sumome.com/" data-sumo-site-id="699cb66cf4dc59352efb45705526d15cbe314e1cd43f7761b94d96f3cf7338e8" async="async"></script> -->
    <link rel="shortcut icon" href="/favicon.ico">
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-01QJCMQM9N"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-01QJCMQM9N');
</script><script src="/js/jquery.js"></script></head><!--/head-->

<!-- Google tag -->





<body id="home" class="homepage" data-spy="scroll" data-offset="100" data-target="#toc">

    <header id="header">
        <nav id="main-menu" class="navbar navbar-default navbar-fixed-top" role="banner">
            <div class="container-fluid">
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="/"><img src="/images/logo.png" alt="logo" style="max-height:66px;float: inherit;
    padding-right: 3px;"></a> 
                    
                   
                </div>
                <div class="collapse navbar-collapse navbar-left">
                    <ul class="nav navbar-nav">
                        <li class="navbar-text pull-left"><strong>TechDocs</strong></li>
                        <p class="navbar-text">
                                            AI Data Capture SDK
                                            1.0
                        </p>

                    </ul>
                </div>
                <div class="collapse navbar-collapse navbar-right">
                    <ul class="nav navbar-nav">
                        


                        <li>
                            <a href="/ai-datacapture/1-0/about">
                                    About
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/localizer">
                                    Localizer
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/productrecognition">
                                    Product Recognition
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/barcodedecoder">
                                    Barcode Decoder
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/textocr">
                                    Text OCR
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/samples">
                                    Samples
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/search">
                                    <i class="fa fa-search"></i>
                            </a>
                        </li>
                        
                        <!-- <li ><a href="/products">SDKs</a></li>
                        <li ><a href="/samples">Samples</a></li>
                        <li ><a href="/guides">Guides</a></li>
                        <li ><a href="/tutorials">Tutorials</a></li>
                        <li ><a href="/apis">APIs</a></li> -->
                        <!-- <li><a href="#"><input type="text" class="st-default-search-input"></a></li> -->
                    </ul>
                </div>
            </div><!--/.container-->
        </nav><!--/nav-->
    </header><!--/header-->
<div class="container-fluid">
    <section id="blog">
        <div class="">
            <section class="content-with-sidebar">
            <div class="row">
                <div class="col-sm-3 hidden-sm hidden-xs" id="sidebar">
                    
                    
                    <nav id="toc" data-toggle="toc" data-spy="affix" style="height: 75%; max-width: 225px; overflow-y: auto; ">
                        
                        <ul class="nav">
                            <li><strong>Text OCR</strong></li>
                        </ul>
                    </nav>
                    <div class="modal fade" id="modal-smartdocs" tabindex="-1" role="dialog" aria-labelledby="basicModal" aria-hidden="true" data-backdrop="true">
                    	<div class="modal-dialog">
                    		<div class="modal-content">
                    			<div class="modal-header">
                    				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">X</button>
                    			</div>
                    			<div class="modal-body">
                    				<form>
                    				  <div class="form-group">
                    				    <label for="exampleInputEmail1">MX Version On Device:</label>
                    				    <select class="form-control">
                    					  <option value="4.0">4.0</option>
                    					  <option value="4.1">4.1</option>
                    					  <option value="4.2">4.2</option>
                    					  <option value="4.3">4.3</option>
                    					  <option value="5.0">5.0</option>
                    					</select>
                    				  </div>						
                    				  <div class="form-group">
                    				    <label for="exampleInputEmail1">OSX Version On Device:</label>
                    				    <select class="form-control">
                    					  <option value="1.0">1.0</option>
                    					  <option value="1.2">1.2</option>
                    					  <option value="1.3.4-56">1.3.4-56</option>
                    					  <option value="3.4">3.4</option>
                    					  <option value="3.5">3.5</option>
                    					  <option value="3.6">3.6</option>
                    					  <option value="4.1">4.1</option>
                    					  <option value="4.2">4.2</option>
                    					  <option value="4.3">4.3</option>
                    					  <option value="4.4">4.4</option>
                    					</select>
                    				  </div>						
                    				  <div class="form-group">
                    				    <label for="exampleInputEmail1">Android Version On Device:</label>
                    				    <select class="form-control">
                    					  <option value="23">6.0 Marshmallow</option>
                    					  <option value="22">5.1 Lollipop</option>
                    					  <option value="21">5.0 Lollipop</option>
                    					  <option value="19">4.4 Kitkat</option>
                    					  <option value="18">4.3 Jellybean</option>
                    					  <option value="17">4.2.x Jellybean</option>
                    					  <option value="16">4.1.x Jellybean</option>
                    					  <option value="15">4.0.3-4.0.4 Ice Cream Sandwich</option>
                    					  <option value="14">4.0-4.0.2 Ice Cream Sandwich</option>
                    					  <option value="10">2.3.3-2.3.4 Gingerbread</option>
                    					</select>
                    				  </div>
                    				  <div class="form-group">
                    				  	<button class="primary" id="btn_SaveSmartDocOptions">Save Changes</button><button class="primary" id="btn_ClearSmartDocOptions">Clear Changes</button>
                    				  </div>
                    				</form>
                    			</div>
                    	</div>
                      </div>
                    </div>
                    
                    <script type="text/javascript">
                        $(document).ready(function() {
                        	$( "#btn_SaveSmartDocOptions" ).click(function() {
                      			console.log('Saving Options');
                      			$("#modal-smartdocs").modal({show: false});
                    		});
                        	$( "#btn_SaveSmartDocOptions" ).click(function() {
                      			console.log('Clearing Options');
                      			$("#modal-smartdocs").modal({show: false});
                    		});
                        });
                    </script><link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v0.3.0/dist/bootstrap-toc.min.css">
                    <script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v0.3.0/dist/bootstrap-toc.min.js"></script>
                    <script type="text/javascript">
                        $(document).ready(function() {
                    
                        });
                    
                    
                    </script>
                </div>                
                <div class="col-sm-9 ">
                    <div class="row">
                        <div class="col-sm-12">
                            <section id="cta" class="wow fadeIn">
                                <div class="">
                                    <h1 id="text-ocr" class="anchor"><a class="heading-anchor" href="#text-ocr"><span></span></a>Text OCR</h1>
                                    <p>
                                            AI Data Capture SDK
                                            1.0
                                    </p>
                                </div>
                            </section>                    
                        </div>
                    </div>
                    <div id="mainContent" class="row">
                        <div class="col-sm-12">
                            <div class="blog-post blog-large wow fadeInLeft" data-wow-duration="300ms" data-wow-delay="0ms">
                            <!-- Start of guide -->
                                <div class="service-box wow fadeInRight">
                                    <div class="">

                                        <p></p><h2 id="overview" class="anchor"><a class="heading-anchor" href="#overview"><span></span></a>Overview</h2>

<p>The <code>TextOCR</code> class is designed for detecting and recognizing text within an image using Optical Character Recognition (OCR) technology. This class provides methods to detect text, words, and paragraphs in various image formats.</p>

<p>The model is adaptable to detecting and recognizing various fonts and adjustment of the input size at initialization to suit different use cases, such as varying distances from the text when capturing images. Smaller input sizes typically yield better results for images with larger or closer text, while larger input sizes enhance detection of smaller or more distant text at the cost of increased inference time. Various methods and options allow customization of output behavior, such as grouping detected words into ‘lines’ or ‘paragraphs.’ </p>

<p>Supported characters include:</p>

<pre class="prettyprint"><code>    *0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&amp;'()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~*
</code></pre>

<p>By default, a maximum word length of approximately 15 characters is supported, although this limit may decrease with uncommon fonts. Enabling <a href="../textocr/#tilingoptions">tiling</a> removes this restriction.</p>

<p><a href="../types/#boundingbox">Bounding boxes</a> are a list of points - a rectangle, but not necessarily perpendicular to the bottom and sides of the screen. There may be more than 4 points if the rectangle has been clipped around the edges of the screen.</p>

<p><strong>Input</strong>: Model and <a href="../types/#image">Image</a></p>

<p><strong>Output</strong>: <a href="../types/#words">OCR Detections</a></p>

<!-- 
## Table of Contents
- [Text OCR](#text-ocr)
  - [Table of Contents](#table-of-contents)
  - [Initialization](#initialization)
  - [Usage](#usage)
  - [Options](#options)
    - [Available Options](#available-options)
      - [Model Configuration](#model-configuration)
      - [Inferencer Options](#inferencer-options)
      - [Detection Parameters](#detection-parameters)
      - [Decoding Options](#decoding-options)
      - [Grouping Options](#grouping-options)
      - [Tiling Options](#tiling-options)
  - [APIs](TextOCR.md#apis) 
-->

<h2 id="initialization" class="anchor"><a class="heading-anchor" href="#initialization"><span></span></a>Initialization</h2>

<p>The <code>TextOCR</code> object is initialized via its configuration structure.</p>

<p><code>MODEL_ARCHIVE_FILEPATH</code> = fully qualified file path to the .tar or .crypt archive from which the OCR model is read.</p>

<p>The user can also optionally override the default model input size (height and width) by specifying the height and width in <code>inferencerOptions</code> in the examples below. The width and height sizes should be multiples of powers of two (e.g., 640). Rule of thumb is that if the user wants to analyze smaller text boxes in the image, the default size needs to be higher. Changing the input size provides a trade-off between accuracy and inference time. Smaller input sizes will run faster but potentially at the loss of accuracy. Larger input sizes will take longer to inference but may give better detection accuracy for use cases where objects are smaller/further away. Additionally, minimum and maximum dimensions can also be provided. This will be helpful if the user is processing images of varying sizes. <strong><em>Note:</em></strong> Model input can be overridden only if <em>resizeDetectorToImage</em> in <a href="#detectionparameters">Detection Parameters</a> is set to false.</p>

<p><strong>For ONNX models:</strong> The user must specify the default width and height, and it is not optional. If the sizes of images are outside the min/max range the detection will fail. If not explicitly set, the min and max dimensions are set to the default dimensions. <em>Caution</em>: Choosing an input size that is too large may cause an out-of-memory situation and crash your application at run-time.</p>

<p>For more advanced inferencer options, refer to <a href="../class/inferenceroptions/">Inferencer Options</a>.</p>

<p>Additional OCR options are available if required. Please look at the <a href="#options">Options</a> for more information.</p>

<pre class="prettyprint"><code>    import com.zebra.AI.Vision.TextOCR;
    &nbsp;
    TextOCR.Settings settings = new TextOCR.Settings(MODEL_ARCHIVE_FILEPATH);
    settings.detectionInferencerOptions.defaultDims.width = 640;
    settings.detectionInferencerOptions.defaultDims.height = 480;
    settings.detectionInferencerOptions.maxDims.width = 1920;
    settings.detectionInferencerOptions.maxDims.height = 1920;
    &nbsp;
    // Initialize OCR object
    TextOCR textocr = new TextOCR(settings);
</code></pre>

<h2 id="usage" class="anchor"><a class="heading-anchor" href="#usage"><span></span></a>Usage</h2>

<p>Detect text on a given image. Output is a collection of <a href="../types/#word">words</a>
or <a href="../types/#paragraph">paragraphs</a>. A paragraph is a collection of words with additional
hierarchical structure, where words appearing on the same line of text are grouped together. The lines
prepared this way are further grouped into paragraphs. The whole process is parameterized and the relevant parameters are described in <a href="#options">Options</a>. The API calls to get both the words
and paragraphs were provided below.</p>

<p><em>IMAGE</em> = Bitmap image</p>

<pre class="prettyprint"><code>    CompletableFuture&lt;Word[ ]&gt; words = textocr.detectWords(IMAGE); // com.zebra.AI.Vision.Word[]
    CompletableFuture&lt;TextParagraph[]&gt; paragraphs = textocr.detectParagraphs(IMAGE); // com.zebra.AI.Vision.TextParagraph[]
</code></pre>

<h2 id="options" class="anchor"><a class="heading-anchor" href="#options"><span></span></a>Options</h2>

<p>The <code>Options</code> structure provides various configuration settings for the TextOCR library. OCR contains a detection stage followed by a recognition stage. These settings allow you to customize the behavior of the OCR process. Below are the available options:</p>

<h3 id="availableoptions" class="anchor"><a class="heading-anchor" href="#availableoptions"><span></span></a>Available Options</h3>

<h4 id="modelconfiguration" class="anchor"><a class="heading-anchor" href="#modelconfiguration"><span></span></a>Model Configuration</h4>

<ol>
<li><p><strong>modelFileLocator</strong></p>

<ul>
<li><strong>Description</strong>: Location of the file with resources for the models and meta values.</li>

<li><strong>Type</strong>: <code>FileLocator</code></li></ul></li>

<li><p><strong>detectionModelName</strong></p>

<ul>
<li><strong>Description</strong>: Name of the detection model in the compressed file.</li>

<li><strong>Type</strong>: <code>string</code></li>

<li><strong>Default</strong>: <code>"det"</code></li></ul></li>

<li><p><strong>recognitionModelName</strong></p>

<p></p><ul>
<li><strong>Description</strong>: Name of the recognition model in the compressed file.</li></ul><p></p>

<p></p></li><li><strong>Type</strong>: <code>string</code></li><p></p>

<p></p><li><strong>Default</strong>: <code>"rec"</code></li><p></p>
</ol>

<h4 id="inferenceroptions" class="anchor"><a class="heading-anchor" href="#inferenceroptions"><span></span></a>Inferencer Options</h4>

<p>Advanced options for inferencer can be found in <a href="../class/inferenceroptions/">inferencer options</a>.</p>

<ol>
<li><p><strong>recognitionInferencerOptions</strong></p>

<ul>
<li><strong>Description</strong>: Options for the recognition inferencer.</li>

<li><strong>Type</strong>: <a href="../class/inferenceroptions/"><code>Inferencer::Options</code></a></li></ul></li>

<li><p><strong>detectionInferencerOptions</strong></p>

<p></p><ul>
<li><strong>Description</strong>: Options for the detection inferencer. The same as for recognition inferencer.</li></ul><p></p>

<p></p></li><li><strong>Type</strong>: <a href="../class/inferenceroptions/"><code>Inferencer::Options</code></a></li><p></p>
</ol>

<h4 id="detectionparameters" class="anchor"><a class="heading-anchor" href="#detectionparameters"><span></span></a>Detection Parameters</h4>

<ol>
<li><strong>heatmapThreshold</strong>


<ul>
<li><strong>Description</strong>: Threshold for detector model output heatmap. The detector model's output is a grayscale image of [0, 1.0] real values, representing the confidence that a given pixel contains text. Raising this threshold value will result in fewer areas being classified as text.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.5f</code></li></ul>
</li>

<li><strong>boxThreshold</strong>


<ul>
<li><strong>Description</strong>: Minimum confidence for a box from heatmap. After thresholding, the resulting bounding boxes are filtered based on their confidence. Raising this parameter will result in fewer bounding boxes being used by OCR.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.85f</code></li></ul>
</li>

<li><strong>minBoxSize</strong>


<ul>
<li><strong>Description</strong>: Minimum size of box side from heatmap. Raising this parameter will filter out the boxes with small width or height.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>1</code></li></ul>
</li>

<li><strong>minBoxArea</strong>


<ul>
<li><strong>Description</strong>: Minimum area of box from heatmap. Raising this parameter will filter out boxes with small area.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>10</code></li></ul>
</li>

<li><strong>resizeDetectorToImage</strong>


<ul>
<li><strong>Description</strong>: Indicates whether to use dynamic detector resolution. Setting this to true will result in the detector being resized to match the input data, not the other way around. This way, even large images can be processed without loss of information.</li>

<li><strong>Type</strong>: <code>bool</code></li>

<li><strong>Default</strong>: <code>false</code> for SNPE models and <code>true</code> for onnx and openvino models.</li>

<li><strong>Example</strong>: If the input image is 1024x1024 and <code>resizeDetectorToImage</code> is true, the detector will resize to 1024x1024. If false, the image will resize to the detector's default size.</li></ul>
</li>

<li><strong>unclipRatio</strong>


<ul>
<li><strong>Description</strong>: A factor of unclipping bounding boxes before the recognition stage. Before doing the OCR, a border is added at the edges of each bounding box to provide better recognition results. Raising this parameter will increase this border and can result in better recognition.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>1.5f</code></li></ul>
</li>

<li><strong>minRatioForRotation</strong>


<ul>
<li><strong>Description</strong>: Minimum ratio of height to width for the word crop to rotate. If <code>0</code>, no rotation will be performed. Otherwise, the boxes with a height to width ratio higher than this value will be rotated 90 degrees (counterclockwise) before recognition.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>1.5f</code></li></ul>
</li>
</ol>

<h4 id="decodingoptions" class="anchor"><a class="heading-anchor" href="#decodingoptions"><span></span></a>Decoding Options</h4>

<ol>
<li><strong>decoderType</strong>


<ul>
<li><strong>Description</strong>: Recognition stage decoding strategy. The OCR algorithm works at the character level. For each character in an image, it predicts multiple characters and their confidences. The decoding strategy decides which of those predictions to choose for each character. Words are created by combining the chosen predictions. All the words along with their corresponding confidences are provided as output.</li>

<li><strong>Type</strong>: <code>OcrDecoderType</code> (see below)</li>

<li><strong>Default</strong>: <code>OcrDecoderType::Total</code></li></ul>
</li>

<li><strong>OcrDecoderType</strong>


<ul>
<li><strong>Description</strong>: Types of decoding strategies available.</li>

<li><strong>Enum Values</strong>:


<ul>
<li><code>Cutoff</code>: Use cutoff decoding strategy. The characters with confidence below a threshold are ignored. This decoding strategy produces only one output.</li>

<li><code>TopK</code>: Use TopK decoding strategy. The decoding is done by considering the top-k predictions for each character and then calculating all possible combinations of the characters along with their joint probabilities.</li>

<li><code>Total</code>: Use total decoding strategy. The decoding is done by considering the characters with cumulative probability greater than a threshold. The characters with cumulative probability below the threshold are ignored. Then, all possible combinations of the characters along with their joint probabilities are calculated.</li></ul>
</li></ul>
</li>

<li><strong>decodingCharacterConfidenceThreshold</strong>


<ul>
<li><strong>Description</strong>: Confidence threshold for single characters (for Cutoff and TopK decodings only). The characters with confidence below a threshold are ignored. Raising the threshold will pick only characters with high confidence. It returns an empty string if it can't find any above the threshold.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.9f</code></li></ul>
</li>

<li><strong>decodingMaxWordCombinations</strong>


<ul>
<li><strong>Description</strong>: The maximum number of possible word outcomes returned in the output. Increasing the number will consider less confident words.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>10</code></li></ul>
</li>

<li><strong>decodingTopKCharacters</strong>


<ul>
<li><strong>Description</strong>: The number of characters to consider for TopK decoding. Increasing the number will consider less confident characters.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>3</code></li></ul>
</li>

<li><strong>decodingTopkIgnoreCutoff</strong>


<ul>
<li><strong>Description</strong>: The maximum number of characters to consider for total decoding. Increasing the value will increase the number of decodes considered for each character.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>4</code></li></ul>
</li>

<li><strong>decodingTotalProbThreshold</strong>


<ul>
<li><strong>Description</strong>: The minimum cumulative sum score of characters required for total decoding. If this threshold is not reached, all characters will be ignored. Increasing the threshold will consider only characters with high cumulative probability.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.9f</code></li></ul>
</li>
</ol>

<p><br></p>

<h4 id="groupingoptions" class="anchor"><a class="heading-anchor" href="#groupingoptions"><span></span></a>Grouping Options</h4>

<p>Grouping works in two stages. Words detected by OCR are grouped into lines that are further grouped into paragraphs as shown in the schema below. Words, lines and paras are represented by blue, green and fuchsia respectively.</p>

<img alt="image" style="height:300px" src="../about/assets/schema.png">
<!-- ![schema](../about/assets/schema.png) -->

<ol>
<li><p><strong>grouping</strong></p>

<ul>
<li><p><strong>Description</strong>: A structure containing parameters for the word into line and line into paragraph grouping.</p></li>

<li><p><strong>Type</strong>: <code>TextOCRGrouper::Options</code></p></li>

<li><p><strong>Fields</strong>:</p>

<ol>
<li><p><strong>widthDistanceRatio</strong></p>

<ul>
<li><strong>Description</strong>: Determines whether the distance between the centers of two words along the x-axis is significantly large. Raising this parameter will cause words that are spaced out horizontally to be joined into a line.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>1.5f</code></li>

<li><strong>Example</strong>: If the average width of words is 90 pixels, setting <code>widthDistanceRatio</code> to 2.0 will allow words up to 180 pixels apart to be grouped into the same line.</li></ul>

<p><img alt="image" style="height:75px" src="../about/assets/widthDistanceRatio.jpg">
<!-- <img src="../about/assets/widthDistanceRatio.jpg" alt="widthDistanceRatio" /> --></p></li><p></p>

<p></p><li><p><strong>heightDistanceRatio</strong></p></li><p></p>

<ul>
<li><strong>Description</strong>: Determines whether there is a significant difference in the height of two words. Raising this parameter will cause words of different heights to be joined into a line.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>2.0f</code></li>

<li><strong>Example</strong>: <code>heightDistanceRatio</code> to 4.0 will allow words with heights in the range of from approximately 0.25 and 4 times the height to be grouped into the same line.</li></ul>

<p><img alt="image" style="height:75px" src="../about/assets/heightDistanceRatio.jpg">
<!-- <img src="../about/assets/heightDistanceRatio.jpg" alt="heightDistanceRatio" /> --></p></ol></li><p></p>

<p></p><li><p><strong>centerDistanceRatio</strong></p></li><p></p>

<ul>
<li><strong>Description</strong>: Determines whether the distance between the centers of two boxes along the y-axis is significantly large. Raising this parameter will cause words that are not strictly aligned in a straight line to be joined into a line object.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.6f</code></li>

<li><strong>Example</strong>: If the average height of words is 20 pixels, setting <code>centerDistanceRatio</code> to 1.0 will allow words with centers up to 20 pixels apart vertically to be grouped into the same line.</li></ul>

<p><img alt="image" style="height:75px" src="../about/assets/centerDistanceRatio.jpg">
<!-- <img src="../about/assets/centerDistanceRatio.jpg" alt="centerDistanceRatio" /> --></p></ul></li><p></p>

<p></p><li><p><strong>paragraphHeightDistance</strong></p></li><p></p>

<ul>
<li><strong>Description</strong>: Determines the difference in the distance between the centers of two rows along the y-axis. Raising this parameter will cause lines that are spaced out vertically to be joined into a paragraph.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>1.0f</code></li>

<li><strong>Example</strong>: If the average height of lines is 30 pixels, setting <code>paragraphHeightDistance</code> to 2 will allow lines with centers up to 60 pixels apart vertically to be grouped into the same paragraph.</li></ul>

<p><img alt="image" style="height:125px" src="../about/assets/paragraphHeightDistance.jpg">
<!-- <img src="../about/assets/paragraphHeightDistance.jpg" alt="paragraphHeightDistance" /> --></p>

<p></p><li><p><strong>paragraphHeightRatioThreshold</strong></p></li><p></p>

<ul>
<li><strong>Description</strong>: Determines whether there is a significant difference in the heights of two rows. Lowering this parameter will cause lines with higher difference in heights to be joined into a paragraph.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>1.0f/3.0f</code></li>

<li><strong>Example</strong>: If the average height of lines is 50 pixels, setting <code>paragraphHeightRatioThreshold</code> to 0.2 will allow lines with heights ranging from approximately 10 pixels to 250 pixels to be grouped into the same paragraph.</li></ul>

<p><img alt="image" style="height:125px" src="../about/assets/paragraphHeightRatioThreshold.jpg">
<!-- <img src="../about/assets/paragraphHeightRatioThreshold.jpg" alt="paragraphHeightRatioThreshold" /> --></p></ol><p></p>


<h4 id="tilingoptions" class="anchor"><a class="heading-anchor" href="#tilingoptions"><span></span></a>Tiling Options</h4>

<ol>
<li><strong>tiling</strong>


<ul>
<li><strong>Description</strong>: A structure containing parameters related to handling very long text boxes.</li>

<li><strong>Type</strong>: <code>OpenCVOcrTiler::Options</code></li>

<li><strong>Fields</strong>:


<ol>
<li><strong>enable</strong>


<ul>
<li><strong>Description</strong>: Enable tiling of elongated text boxes. Boxes that match aspect ratio criteria will be split into multiple images (tiles) and recognition will be performed on each of them. After that, a correlation method will be used to merge the results of recognition into a single set of decodes. Enabling this option may help recognize text in long strings of characters.</li>

<li><strong>Type</strong>: <code>bool</code></li>

<li><strong>Default</strong>: <code>false</code></li></ul>
</li>

<li><strong>topCorrelationThr</strong>


<ul>
<li><strong>Description</strong>: Increasing this value will reduce the number of combinations used internally to perform tiling based on their confidence. Tuning this value may increase/decrease tiling result accuracy. Setting it to 0 will turn this feature off.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.0f</code></li>

<li><strong>Valid range</strong>: <code>[0.0f, 1.0f]</code></li></ul>
</li>

<li><strong>mergePointsCutoff</strong>


<ul>
<li><strong>Description</strong>: This is an internal parameter used to limit the number of possible combinations used for tile merging. Raising this value will result in more combinations being used internally and will increase the processing time but can also generate more accurate results.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>5</code></li></ul>
</li>

<li><strong>splitMarginFactor</strong>


<ul>
<li><strong>Description</strong>: This parameter scales the confidence values for characters that are at the borders of consecutive tiles, assuming that characters that these characters could be deformed due to cutting the image into tiles. It's not recommended to modify this value.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.1f</code></li>

<li><strong>Valid range</strong>: <code>[0.0f, 1.0f]</code></li></ul>
</li>

<li><strong>aspectRatioLowerThr</strong>


<ul>
<li><strong>Description</strong>: Tiling algorithm decides which boxes should be tiled and which not. Lowering this threshold will result with more boxes, with smaller aspect ratio (width/height) being tiled. Lowering this value can result in increased processing time.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>10.0f</code></li></ul>
</li>

<li><strong>aspectRatioUpperThr</strong>


<ul>
<li><strong>Description</strong>: This threshold alows filtering of boxes with very high aspect ratio. Such boxes rarely occur naturally and sometimes are a false positive of text detector model. Lowering this value will result in less boxes being tiled.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>40.0f</code></li></ul>
</li>

<li><strong>topkMergedPredictions</strong>


<ul>
<li><strong>Description</strong>: The final tiling result - the decodes, are sorted based on their confidence score. This setting allows the user to limit the number of decodes being returned from the OCR.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>5</code></li></ul>
</li></ol>
</li></ul>
</li>
</ol>

<p><br></p>

<p>TextOCR.md#textocrsettingssettings</p>

<!-- 
## APIs
The following is a list of APIs supported by TextOCR.
Return Type                          |  API Name
-------------------------------------| --------------------------------------
TextOCR       | [TextOCR](TextOCR.md#textocrsettingssettings)   ([Settings](TextOCRSettings.md) settings) throws FileNotFoundException, IOException
CompletableFuture<[OCRResult](OCRResult.md)[]> | [detect](TextOCR.md#detect-bitmapsrcimg) (Bitmap srcImg) throws InvalidInputException
CompletableFuture<[Word](Word.md)[]> |    [detectWords](TextOCR.md#detectwordsbitmapsrcimg) (Bitmap srcImg) throws InvalidInputException
CompletableFuture<[TextParagraph](TextParagraph.md)[]> |    [detectParagraphs](TextOCR.md#detectparagraphs-bitmapsrcimg) (Bitmap srcImg) throws InvalidInputException
void      | [dispose](TextOCR.md#dispose-) ()
-->

<h2 id="apis" class="anchor"><a class="heading-anchor" href="#apis"><span></span></a>APIs</h2>

<p>The <code>TextOCR</code> class is part of the <code>com.zebra.AI.Vision</code> package and is used for detecting and recognizing text in images. It provides methods for detecting text at different granularities, including words and paragraphs. This class is essential for applications that require text extraction from images, such as document scanning, automated data entry, and more.</p>

<h3 id="textocrsettingssettings" class="anchor"><a class="heading-anchor" href="#textocrsettingssettings"><span></span></a>TextOCR(Settings settings)</h3>

<p>Initializes the OCR engine with the specified settings, allowing subsequent text detection and analysis on image inputs. It validates the availability of required model files and ensures the integrity of the archive. If any issues are detected, appropriate exceptions are thrown.</p>

<ul>
<li><strong>Constructor:</strong>


<ul>
<li>TextOCR.TextOCR (<a href="../textocr/textocrsettings/">Settings</a> settings) throws FileNotFoundException, IOException</li></ul>
</li>

<li><strong>Parameters:</strong></li>

<li><code>settings</code> - <a href="../textocr/textocrsettings/">TextOCR.Settings settings</a> to construct an OCR object with.
An instance of the <code>Settings</code> class, containing configuration options for the OCR engine. These settings include model paths, language preferences, and performance configurations.</li>

<li><strong>Exceptions:</strong>


<ul>
<li><code>FileNotFoundException</code> - Thrown if the required model file is not found in the archive.</li>

<li><code>IOException</code> - Thrown if the archive is corrupted.</li></ul>
</li>
</ul>

<h3 id="detectbitmapsrcimg" class="anchor"><a class="heading-anchor" href="#detectbitmapsrcimg"><span></span></a>detect (Bitmap srcImg)</h3>

<p>Performs Optical Character Recognition (OCR) on the provided Bitmap image.</p>

<ul>
<li><strong>Method:</strong>


<ul>
<li><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html">CompletableFuture</a>&lt;<a href="../class/ocrresult/">OCRResult</a>[ ]&gt; TextOCR.detect (Bitmap srcImg) throws <a href="../class/invalidinputexception/">InvalidInputException</a></li></ul>
</li>

<li><strong>Parameters:</strong>


<ul>
<li><code>srcImg</code> (Bitmap srcImg) - A <code>Bitmap</code> image to perform OCR detection on.</li></ul>
</li>

<li><strong>Return Value:</strong>


<ul>
<li>An array of <a href="../class/ocrresult/">OCRResult</a> containing bounding boxes and recognized text.</li></ul>
</li>

<li><strong>Exceptions:</strong>


<ul>
<li><code>InvalidInputException</code> - Thrown when Bitmap is passed as null. </li></ul>
</li>
</ul>

<h3 id="detectwordsbitmapsrcimg" class="anchor"><a class="heading-anchor" href="#detectwordsbitmapsrcimg"><span></span></a>detectWords(Bitmap    srcImg)</h3>

<h4 id="apiname" class="anchor"><a class="heading-anchor" href="#apiname"><span></span></a>API Name</h4>

<p><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html">CompletableFuture</a>&lt;<a href="../class/word/">Word</a>[ ]&gt; TextOCR.detectWords(Bitmap    srcImg) throws <a href="../class/invalidinputexception/">InvalidInputException</a>
<strong>Description</strong>
Detects individual words in the given Bitmap image. Each word may have multiple possible readings with associated confidence scores.
<strong>Parameters</strong></p>

<ul>
<li><code>srcImg</code> (Bitmap srcImg) - The image to analyze for word detection.
<strong>Exceptions</strong>
<code>InvalidInputException</code></li>
</ul>

<p>Throws <code>InvalidInputException</code> exception when Bitmap is passed as null. 
<strong>Return Value</strong>
An array of <code>Words</code> objects containing bounding boxes and possible text decodes.</p>

<h3 id="detectparagraphsbitmapsrcimg" class="anchor"><a class="heading-anchor" href="#detectparagraphsbitmapsrcimg"><span></span></a>detectParagraphs (Bitmap    srcImg)</h3>

<p>Detects paragraphs in the given Bitmap image. Words are grouped into lines and paragraphs based on layout.</p>

<ul>
<li><strong>Prototype:</strong>


<ul>
<li><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html">CompletableFuture</a>&lt;<a href="../class/textparagraph/">TextParagraph</a>[ ]&gt; TextOCR.detectParagraphs (Bitmap    srcImg) throws <a href="../class/invalidinputexception/">InvalidInputException</a></li></ul>
</li>

<li><strong>Parameters:</strong>


<ul>
<li><code>srcImg</code> (Bitmap srcImg): The image to analyze for paragraph detection.</li></ul>
</li>

<li><strong>Return Value:</strong>


<ul>
<li>An array of <code>TextParagraph</code> objects representing detected paragraphs.</li></ul>
</li>

<li><strong>Exceptions:</strong> 


<ul>
<li><code>InvalidInputException</code> - Thrown when Bitmap is passed as null. </li></ul>
</li>
</ul>

<h3 id="dispose" class="anchor"><a class="heading-anchor" href="#dispose"><span></span></a>dispose ()</h3>

<p>Releases all internal resources used by the <code>TextOCR</code> object. This function needs to be called manually to free up resources.</p>

<ul>
<li><strong>Constructor:</strong>


<ul>
<li>void dispose()</li></ul>
</li>
</ul><p></p>
                                        


                                    </div>
                                </div>

                            </div>
                        </div>
                    </div>
                </div><!--/.col-sm-6-->
            </div>
            </section>
        </div>
    </section>    

<div class="modal fade" id="basicModal" tabindex="-1" role="dialog" aria-labelledby="basicModal" aria-hidden="true" data-backdrop="true">
			<div class="modal-dialog">
				<div class="modal-content">
					<div class="modal-header">
						<button type="button" class="close" data-dismiss="modal" aria-hidden="true">X</button>
					</div>
					<div class="modal-body">
						<div id="modalImg">
						
						</div>
					</div>
			</div>
		  </div>
		</div> </div>
         <footer id="footer">
            <div class="container-fluid">
                <div class="row">
                    <div class="col-sm-10">
                        ZEBRA and the stylized Zebra head are trademarks of Zebra Technologies Corp., registered in many jurisdictions worldwide. All other trademarks are the property of their respective owners. ©2024 Zebra Technologies Corp. and/or its affiliates.<br> <a href="https://www.zebra.com/us/en/about-zebra/company-information/legal.html">Legal</a> | <a href="https://www.zebra.com/us/en/about-zebra/company-information/compliance/information-privacy/terms-of-use.html">Terms of Use</a> | <a href="https://www.zebra.com/us/en/about-zebra/company-information/legal/privacy-statement.html">Privacy Policy</a> 
                    </div>
                     <!--
                     <div class="col-sm-2">
                        <ul class="social-icons">
                            <li><a href="http://www.facebook.com/pages/Zebra-Technologies/107703715989073"><i class="fa fa-facebook"></i></a></li>
                            <li><a href="https://twitter.com/ZebraDevs"><i class="fa fa-twitter"></i></a></li>
                            <li><a href="http://www.youtube.com/zebratechnologies/"><i class="fa fa-youtube"></i></a></li>
                            <li><a href="https://www.linkedin.com/groups?home=&gid=3220074&trk=anet_ug_hm&goback=%2Egmr_3220074"><i class="fa fa-linkedin"></i></a></li>
                            <li><a href="https://github.com/developer-zebra"><i class="fa fa-github"></i></a></li>
                        </ul>
                    </div> -->
                 </div>
            </div>
        </footer>
    
    <!--/#footer 
        10/25/18 removed <footer id="footer" class="navbar-fixed-bottom">
    -->
    <script src="/js/bootstrap.min.js"></script>
    <script src="/js/owl.carousel.min.js"></script>
    <script src="/js/mousescroll.js"></script>
    <script src="/js/smoothscroll.js"></script>
    <script src="/js/jquery.prettyPhoto.js"></script>
    <script src="/js/jquery.isotope.min.js"></script>
    <script src="/js/jquery.inview.min.js"></script>
    <script src="/js/wow.min.js"></script>
    <script src="/js/bootstrap-treenav.min.js"></script>
    <script src="/js/prettify.js"></script>
    <script src="/js/zepto.js"></script>
    <script src="/js/jquery.waterfall.js"></script>   
    <script src="/js/main.js"></script>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install','zRzEsAUhWTTkrdEN2YfA','2.0.0');
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-72584442-1', 'auto');
  ga('send', 'pageview');

</script> 

<script>
    ChatraID = 'QDvZ76min4DhLW5vJ';
    (function(d, w, c) {
        var n = d.getElementsByTagName('script')[0],
            s = d.createElement('script');
        w[c] = w[c] || function() {
            (w[c].q = w[c].q || []).push(arguments);
        };
        s.async = true;
        s.src = (d.location.protocol === 'https:' ? 'https:': 'http:')
            + '//call.chatra.io/chatra.js';
        n.parentNode.insertBefore(s, n);
    })(document, window, 'Chatra');
</script>         


</body></html>