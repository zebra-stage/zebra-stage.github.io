
<!DOCTYPE html>
<html lang="en"><head>

    <meta charset="utf-8">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="-1">
    <meta http-equiv="CACHE-CONTROL" content="NO-CACHE">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Online Documentation for Zebra Technologies developer tools and utilties, including EMDK for Android, EMDK for Xamarin, StageNow and Enterprise Browser.">
    <meta name="author" content="Zebra Technologies">
    <meta name="google-site-verification" content="i4B78BrWnNy8ShJwe5feRW3jO3HE6gfYlYqYbxfl8yY">
    <meta name="msvalidate.01" content="6B651B00161BCE79B8950AC09D5C4C75">
    <meta title="Text OCR">
    <title>Text OCR - TechDocs</title>
    <!-- core CSS -->
    <link href="/css/bootstrap.min.css" rel="stylesheet">
<!--     
    <link href="/css/font-awesome.min.css" rel="stylesheet">
 -->    
    <link href="/css/all.css" rel="stylesheet">
    <link href="/css/v4-shims.css" rel="stylesheet">
    <link href="/css/animate.min.css" rel="stylesheet">
    <link href="/css/owl.carousel.css" rel="stylesheet">
    <link href="/css/owl.transitions.css" rel="stylesheet">
    <link href="/css/prettyPhoto.css" rel="stylesheet">
    <link href="/css/main.css" rel="stylesheet">
    <link href="/css/responsive.css" rel="stylesheet">
    <link href="/css/prettify.css" rel="stylesheet">
    <link href="/css/bootstrap-treenav.min.css" rel="stylesheet">
    <!--[if lt IE 9]>
    <script src="js/html5shiv.js"></script>
    <script src="js/respond.min.js"></script>
    <![endif]--> 

    <!-- 6/13/24- a "crown" icon randomly appeared in the MX matrix today. Rob said it looked like sumo. 
        <script src="//load.sumome.com/" data-sumo-site-id="699cb66cf4dc59352efb45705526d15cbe314e1cd43f7761b94d96f3cf7338e8" async="async"></script> -->
    <link rel="shortcut icon" href="/favicon.ico">
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-01QJCMQM9N"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-01QJCMQM9N');
</script><script src="/js/jquery.js"></script></head><!--/head-->

<!-- Google tag -->





<body id="home" class="homepage" data-spy="scroll" data-offset="100" data-target="#toc">

    <header id="header">
        <nav id="main-menu" class="navbar navbar-default navbar-fixed-top" role="banner">
            <div class="container-fluid">
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="/"><img src="/images/logo.png" alt="logo" style="max-height:66px;float: inherit;
    padding-right: 3px;"></a> 
                    
                   
                </div>
                <div class="collapse navbar-collapse navbar-left">
                    <ul class="nav navbar-nav">
                        <li class="navbar-text pull-left"><strong>TechDocs</strong></li>
                        <p class="navbar-text">
                                            AI Data Capture SDK
                                            1.0
                        </p>

                    </ul>
                </div>
                <div class="collapse navbar-collapse navbar-right">
                    <ul class="nav navbar-nav">
                        


                        <li>
                            <a href="/ai-datacapture/1-0/about">
                                    About
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/localizer">
                                    Localizer
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/productrecognition">
                                    Product Recognition
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/barcodedecoder">
                                    Barcode Decoder
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/textocr">
                                    Text OCR
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/samples">
                                    Samples
                            </a>
                        </li>
                        <li>
                            <a href="/ai-datacapture/1-0/search">
                                    <i class="fa fa-search"></i>
                            </a>
                        </li>
                        
                        <!-- <li ><a href="/products">SDKs</a></li>
                        <li ><a href="/samples">Samples</a></li>
                        <li ><a href="/guides">Guides</a></li>
                        <li ><a href="/tutorials">Tutorials</a></li>
                        <li ><a href="/apis">APIs</a></li> -->
                        <!-- <li><a href="#"><input type="text" class="st-default-search-input"></a></li> -->
                    </ul>
                </div>
            </div><!--/.container-->
        </nav><!--/nav-->
    </header><!--/header-->
<div class="container-fluid">
    <section id="blog">
        <div class="">
            <section class="content-with-sidebar">
            <div class="row">
                <div class="col-sm-3 hidden-sm hidden-xs" id="sidebar">
                    
                    
                    <nav id="toc" data-toggle="toc" data-spy="affix" style="height: 75%; max-width: 225px; overflow-y: auto; ">
                        
                        <ul class="nav">
                            <li><strong>Text OCR</strong></li>
                        </ul>
                    </nav>
                    <div class="modal fade" id="modal-smartdocs" tabindex="-1" role="dialog" aria-labelledby="basicModal" aria-hidden="true" data-backdrop="true">
                    	<div class="modal-dialog">
                    		<div class="modal-content">
                    			<div class="modal-header">
                    				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">X</button>
                    			</div>
                    			<div class="modal-body">
                    				<form>
                    				  <div class="form-group">
                    				    <label for="exampleInputEmail1">MX Version On Device:</label>
                    				    <select class="form-control">
                    					  <option value="4.0">4.0</option>
                    					  <option value="4.1">4.1</option>
                    					  <option value="4.2">4.2</option>
                    					  <option value="4.3">4.3</option>
                    					  <option value="5.0">5.0</option>
                    					</select>
                    				  </div>						
                    				  <div class="form-group">
                    				    <label for="exampleInputEmail1">OSX Version On Device:</label>
                    				    <select class="form-control">
                    					  <option value="1.0">1.0</option>
                    					  <option value="1.2">1.2</option>
                    					  <option value="1.3.4-56">1.3.4-56</option>
                    					  <option value="3.4">3.4</option>
                    					  <option value="3.5">3.5</option>
                    					  <option value="3.6">3.6</option>
                    					  <option value="4.1">4.1</option>
                    					  <option value="4.2">4.2</option>
                    					  <option value="4.3">4.3</option>
                    					  <option value="4.4">4.4</option>
                    					</select>
                    				  </div>						
                    				  <div class="form-group">
                    				    <label for="exampleInputEmail1">Android Version On Device:</label>
                    				    <select class="form-control">
                    					  <option value="23">6.0 Marshmallow</option>
                    					  <option value="22">5.1 Lollipop</option>
                    					  <option value="21">5.0 Lollipop</option>
                    					  <option value="19">4.4 Kitkat</option>
                    					  <option value="18">4.3 Jellybean</option>
                    					  <option value="17">4.2.x Jellybean</option>
                    					  <option value="16">4.1.x Jellybean</option>
                    					  <option value="15">4.0.3-4.0.4 Ice Cream Sandwich</option>
                    					  <option value="14">4.0-4.0.2 Ice Cream Sandwich</option>
                    					  <option value="10">2.3.3-2.3.4 Gingerbread</option>
                    					</select>
                    				  </div>
                    				  <div class="form-group">
                    				  	<button class="primary" id="btn_SaveSmartDocOptions">Save Changes</button><button class="primary" id="btn_ClearSmartDocOptions">Clear Changes</button>
                    				  </div>
                    				</form>
                    			</div>
                    	</div>
                      </div>
                    </div>
                    
                    <script type="text/javascript">
                        $(document).ready(function() {
                        	$( "#btn_SaveSmartDocOptions" ).click(function() {
                      			console.log('Saving Options');
                      			$("#modal-smartdocs").modal({show: false});
                    		});
                        	$( "#btn_SaveSmartDocOptions" ).click(function() {
                      			console.log('Clearing Options');
                      			$("#modal-smartdocs").modal({show: false});
                    		});
                        });
                    </script><link rel="stylesheet" href="https://cdn.rawgit.com/afeld/bootstrap-toc/v0.3.0/dist/bootstrap-toc.min.css">
                    <script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v0.3.0/dist/bootstrap-toc.min.js"></script>
                    <script type="text/javascript">
                        $(document).ready(function() {
                    
                        });
                    
                    
                    </script>
                </div>                
                <div class="col-sm-9 ">
                    <div class="row">
                        <div class="col-sm-12">
                            <section id="cta" class="wow fadeIn">
                                <div class="">
                                    <h1 id="text-ocr" class="anchor"><a class="heading-anchor" href="#text-ocr"><span></span></a>Text OCR</h1>
                                    <p>
                                            AI Data Capture SDK
                                            1.0
                                    </p>
                                </div>
                            </section>                    
                        </div>
                    </div>
                    <div id="mainContent" class="row">
                        <div class="col-sm-12">
                            <div class="blog-post blog-large wow fadeInLeft" data-wow-duration="300ms" data-wow-delay="0ms">
                            <!-- Start of guide -->
                                <div class="service-box wow fadeInRight">
                                    <div class="">

                                        <p></p><h2 id="overview" class="anchor"><a class="heading-anchor" href="#overview"><span></span></a>Overview</h2>

<p>The <code>TextOCR</code> class detects and recognizes text within images using Optical Character Recognition (OCR) technology. It provides methods for identifying text, words, and paragraphs across various image formats. Various methods and options allow customization of output behavior, such as grouping detected words into ‘lines’ or ‘paragraphs.’ </p>

<p>Supported characters:</p>

<pre class="prettyprint"><code>    *0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&amp;'()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~*
</code></pre>

<p>By default, a maximum word length of approximately 15 characters is supported, although this limit may decrease with uncommon fonts. Enabling <a href="../textocr/#tilingoptions">tiling</a> removes this restriction.</p>

<p><strong>Input Parameters:</strong> The default model input size is 640x640. The input size can be changed during runtime initialization. 
    - <strong>Larger Input Sizes -</strong> Improves accuracy for smaller or more distant text, but results to increased inference time.
    - <strong>Smaller Input Sizes -</strong> Less data is being processed, leading to faster inference speed but with less accuracy. Typically yields better results for larger or closer text.
<strong>Output Parameters:</strong> A list of text detections, each with a list of bounding boxes outlining the detection and the text contained within.</p>

<!-- 
## Table of Contents
- [Text OCR](#text-ocr)
  - [Table of Contents](#table-of-contents)
  - [Initialization](#initialization)
  - [Usage](#usage)
  - [Options](#options)
    - [Available Options](#available-options)
      - [Model Configuration](#model-configuration)
      - [Inferencer Options](#inferencer-options)
      - [Detection Parameters](#detection-parameters)
      - [Decoding Options](#decoding-options)
      - [Grouping Options](#grouping-options)
      - [Tiling Options](#tiling-options)
  - [APIs](TextOCR.md#apis) 
-->

<h2 id="initialization" class="anchor"><a class="heading-anchor" href="#initialization"><span></span></a>Initialization</h2>

<p>The <code>TextOCR</code> object is initialized via its configuration structure. Users can optionally override the default model input size (height and width) via <code>inferencerOptions</code>; see the examples below. Sizes should be expressed in powers of two (e.g., 640). Larger sizes improve accuracy for smaller text (further away) but increase inference time. Smaller sizes improve speed, but may decrease accuracy. Minimum and maximum dimensions can be set for processing varied image sizes. <strong>Note:</strong> Model input can only be overridden if <code>resizeDetectorToImage</code> is set to false in <a href="#detectionparameters">Detection Parameters</a>.</p>

<p><strong>For ONNX models:</strong> Specifying the default height and width is mandatory. If image sizes are outside the min/max range, detection fails. If not explicitly set, the min/max dimensions are set to defaults. <strong>Note:</strong> Excessive input size may cause out-of-memory error and crash the application.</p>

<p>For advanced inferencer options, refer to <a href="../class/inferenceroptions/">Inferencer Options</a>. Additional OCR options are available in <a href="#options">Options</a>.</p>

<pre class="prettyprint"><code>    import com.zebra.AI.Vision.TextOCR;
    &nbsp;
    TextOCR.Settings settings = new TextOCR.Settings(MODEL_ARCHIVE_FILEPATH);
    settings.detectionInferencerOptions.defaultDims.width = 640;
    settings.detectionInferencerOptions.defaultDims.height = 480;
    settings.detectionInferencerOptions.maxDims.width = 1920;
    settings.detectionInferencerOptions.maxDims.height = 1920;
    &nbsp;
    // Initialize OCR object
    TextOCR textocr = new TextOCR(settings);
</code></pre>

<p><code>MODEL_ARCHIVE_FILEPATH</code> represents the fully qualified file path to the .tar or .crypt archive from which the OCR model is read.</p>

<h2 id="usage" class="anchor"><a class="heading-anchor" href="#usage"><span></span></a>Usage</h2>

<p>Detect text in an image, outputting words or paragraphs. A paragraph is a collection of words with additional hierarchical structure, where words on the same line are grouped into lines, and lines into paragraphs. This process is parameterized, with relevant parameters described in <a href="#options">Options</a>.</p>

<p>Sample API calls to retrieve both words and paragraphs:</p>

<pre class="prettyprint"><code>    CompletableFuture&lt;Word[]&gt; words = textocr.detectWords(IMAGE); // com.zebra.AI.Vision.Word[]
    CompletableFuture&lt;TextParagraph[]&gt; paragraphs = textocr.detectParagraphs(IMAGE); // com.zebra.AI.Vision.TextParagraph[]
</code></pre>

<p><code>IMAGE</code> represents the bitmap image.</p>

<h3 id="definitions" class="anchor"><a class="heading-anchor" href="#definitions"><span></span></a>Definitions</h3>

<p>Definitions for key terms:</p>

<ul>
<li><strong>Bounding box -</strong> A list of points forming a rectangle, which may not be perpendicular to the bottom and sides of the screen. More than 4 points can be present if the rectangle is clipped at the edges of the screen. Each bounding box includes:


<ul>
<li><strong>Coordinates of the bounding rectangle -</strong> Defines the position and size of the detected object.</li>

<li><strong>Probability (Confidence) -</strong> Indicates the certainty of the detection.</li>

<li><strong>Class -</strong> Specifies the type of object detected.</li></ul>
</li>

<li><strong>Paragraph -</strong> Contains a complex bounding box and an array of lines.</li>

<li><strong>Line -</strong> Contains a complex bounding box and an array of words.</li>

<li><strong>Word -</strong> Contains a complex bounding box and an array of decodes.</li>

<li><strong>Decode -</strong> Contains decoded text strings (referred to as content) and their confidence.</li>
</ul>

<h2 id="options" class="anchor"><a class="heading-anchor" href="#options"><span></span></a>Options</h2>

<p>The <code>Options</code> structure provides configuration settings for the <code>TextOCR</code> library, containing a detection and recognition stage. These settings customize OCR behavior.</p>

<h3 id="modelconfiguration" class="anchor"><a class="heading-anchor" href="#modelconfiguration"><span></span></a>Model Configuration</h3>

<ol>
<li><strong>modelFileLocator</strong>


<ul>
<li><strong>Description</strong>: Location of the file containing resources for the models and meta values.</li>

<li><strong>Type</strong>: <code>FileLocator</code></li></ul>
</li>

<li><strong>detectionModelName</strong>


<ul>
<li><strong>Description</strong>: Name of the detection model in the compressed file.</li>

<li><strong>Type</strong>: <code>string</code></li>

<li><strong>Default</strong>: <code>"det"</code></li></ul>
</li>

<li><strong>recognitionModelName</strong>


<ul>
<li><strong>Description</strong>: Name of the recognition model in the compressed file.</li>

<li><strong>Type</strong>: <code>string</code></li>

<li><strong>Default</strong>: <code>"rec"</code></li></ul>
</li>
</ol>

<h3 id="inferenceroptions" class="anchor"><a class="heading-anchor" href="#inferenceroptions"><span></span></a>Inferencer Options</h3>

<p>Advanced options for inferencer can be found in <a href="../class/inferenceroptions/">inferencer options</a>.</p>

<ol>
<li><strong>recognitionInferencerOptions</strong>


<ul>
<li><strong>Description</strong>: Options for the recognition inferencer.</li>

<li><strong>Type</strong>: <a href="../class/inferenceroptions/"><code>Inferencer::Options</code></a></li></ul>
</li>

<li><strong>detectionInferencerOptions</strong>


<ul>
<li><strong>Description</strong>: Options for the detection inferencer. The same as for recognition inferencer.</li>

<li><strong>Type</strong>: <a href="../class/inferenceroptions/"><code>Inferencer::Options</code></a></li></ul>
</li>
</ol>

<h3 id="detectionparameters" class="anchor"><a class="heading-anchor" href="#detectionparameters"><span></span></a>Detection Parameters</h3>

<ol>
<li><strong>heatmapThreshold</strong>


<ul>
<li><strong>Description</strong>: Threshold for detector model output heatmap. The detector model's output is a grayscale image of [0, 1.0] real values, representing the confidence that a given pixel contains text. Raising this threshold value results in fewer areas being classified as text.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.5f</code></li></ul>
</li>

<li><strong>boxThreshold</strong>


<ul>
<li><strong>Description</strong>: Minimum confidence for a box from heatmap. After thresholding, the resulting bounding boxes are filtered based on their confidence. Raising this parameter will result in fewer bounding boxes being used by OCR.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.85f</code></li></ul>
</li>

<li><strong>minBoxSize</strong>


<ul>
<li><strong>Description</strong>: Minimum size of box side from heatmap. Raising this parameter will filter out the boxes with small width or height.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>1</code></li></ul>
</li>

<li><strong>minBoxArea</strong>


<ul>
<li><strong>Description</strong>: Minimum area of box from heatmap. Raising this parameter will filter out boxes with small area.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>10</code></li></ul>
</li>

<li><strong>resizeDetectorToImage</strong>


<ul>
<li><strong>Description</strong>: Indicates whether to use dynamic detector resolution. Setting this to true will result in the detector being resized to match the input data, not the other way around. This way, even large images can be processed without loss of information.</li>

<li><strong>Type</strong>: <code>bool</code></li>

<li><strong>Default</strong>: <code>false</code> for SNPE models and <code>true</code> for onnx and openvino models.</li>

<li><strong>Example</strong>: If the input image is 1024x1024 and <code>resizeDetectorToImage</code> is true, the detector will resize to 1024x1024. If false, the image will resize to the detector's default size.</li></ul>
</li>

<li><strong>unclipRatio</strong>


<ul>
<li><strong>Description</strong>: A factor of unclipping bounding boxes before the recognition stage. Before doing the OCR, a border is added at the edges of each bounding box to provide better recognition results. Raising this parameter will increase this border and can result in better recognition.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>1.5f</code></li></ul>
</li>

<li><strong>minRatioForRotation</strong>


<ul>
<li><strong>Description</strong>: Minimum ratio of height to width for the word crop to rotate. If <code>0</code>, no rotation will be performed. Otherwise, the boxes with a height to width ratio higher than this value will be rotated 90 degrees (counterclockwise) before recognition.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>1.5f</code></li></ul>
</li>
</ol>

<h3 id="decodingoptions" class="anchor"><a class="heading-anchor" href="#decodingoptions"><span></span></a>Decoding Options</h3>

<ol>
<li><strong>decoderType</strong>


<ul>
<li><strong>Description</strong>: Recognition stage decoding strategy. The OCR algorithm works at the character level. For each character in an image, it predicts multiple characters and their confidences. The decoding strategy decides which of those predictions to choose for each character. Words are created by combining the chosen predictions. All the words along with their corresponding confidences are provided as output.</li>

<li><strong>Type</strong>: <code>OcrDecoderType</code> (see below)</li>

<li><strong>Default</strong>: <code>OcrDecoderType::Total</code></li></ul>
</li>

<li><strong>OcrDecoderType</strong>


<ul>
<li><strong>Description</strong>: Types of decoding strategies available.</li>

<li><strong>Enum Values</strong>:


<ul>
<li><code>Cutoff</code>: Use cutoff decoding strategy. The characters with confidence below a threshold are ignored. This decoding strategy produces only one output.</li>

<li><code>TopK</code>: Use TopK decoding strategy. The decoding is done by considering the top-k predictions for each character and then calculating all possible combinations of the characters along with their joint probabilities.</li>

<li><code>Total</code>: Use total decoding strategy. The decoding is done by considering the characters with cumulative probability greater than a threshold. The characters with cumulative probability below the threshold are ignored. Then, all possible combinations of the characters along with their joint probabilities are calculated.</li></ul>
</li></ul>
</li>

<li><strong>decodingCharacterConfidenceThreshold</strong>


<ul>
<li><strong>Description</strong>: Confidence threshold for single characters (for Cutoff and TopK decodings only). The characters with confidence below a threshold are ignored. Raising the threshold will pick only characters with high confidence. It returns an empty string if it can't find any above the threshold.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.9f</code></li></ul>
</li>

<li><strong>decodingMaxWordCombinations</strong>


<ul>
<li><strong>Description</strong>: The maximum number of possible word outcomes returned in the output. Increasing the number will consider less confident words.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>10</code></li></ul>
</li>

<li><strong>decodingTopKCharacters</strong>


<ul>
<li><strong>Description</strong>: The number of characters to consider for TopK decoding. Increasing the number will consider less confident characters.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>3</code></li></ul>
</li>

<li><strong>decodingTopkIgnoreCutoff</strong>


<ul>
<li><strong>Description</strong>: The maximum number of characters to consider for total decoding. Increasing the value will increase the number of decodes considered for each character.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>4</code></li></ul>
</li>

<li><strong>decodingTotalProbThreshold</strong>


<ul>
<li><strong>Description</strong>: The minimum cumulative sum score of characters required for total decoding. If this threshold is not reached, all characters will be ignored. Increasing the threshold will consider only characters with high cumulative probability.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.9f</code></li></ul>
</li>
</ol>

<p><br></p>

<h3 id="groupingoptions" class="anchor"><a class="heading-anchor" href="#groupingoptions"><span></span></a>Grouping Options</h3>

<p>Grouping works in two stages. Words detected by OCR are grouped into lines that are further grouped into paragraphs as shown in the schema below. Words, lines and paragraphs in the graphics below are represented by blue, green and fuchsia colored borders respectively.</p>

<img alt="image" style="height:300px" src="../about/assets/schema.png">
<!-- ![schema](../about/assets/schema.png) -->

<p><strong>grouping</strong></p>

<ul>
<li><p><strong>Description</strong>: A structure containing parameters for the word into line and line into paragraph grouping.</p></li>

<li><p><strong>Type</strong>: <code>TextOCRGrouper::Options</code></p></li>

<li><p><strong>Fields</strong>:</p>

<ol>
<li><p><strong>widthDistanceRatio</strong></p>

<ul>
<li><strong>Description</strong>: Determines whether the distance between the centers of two words along the x-axis is significantly large. Raising this parameter will cause words that are spaced out horizontally to be joined into a line.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>1.5f</code></li>

<li><strong>Example</strong>: If the average width of words is 90 pixels, setting <code>widthDistanceRatio</code> to 2.0 will allow words up to 180 pixels apart to be grouped into the same line.</li></ul>

<img alt="image" style="height:75px" src="../about/assets/widthDistanceRatio.jpg">
<!-- ![widthDistanceRatio](../about/assets/widthDistanceRatio.jpg) --></li>

<li><p><strong>heightDistanceRatio</strong></p>

<ul>
<li><strong>Description</strong>: Determines whether there is a significant difference in the height of two words. Raising this parameter will cause words of different heights to be joined into a line.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>2.0f</code></li>

<li><strong>Example</strong>: <code>heightDistanceRatio</code> to 4.0 will allow words with heights in the range of from approximately 0.25 and 4 times the height to be grouped into the same line.</li></ul>

<img alt="image" style="height:75px" src="../about/assets/heightDistanceRatio.jpg">
<!-- ![heightDistanceRatio](../about/assets/heightDistanceRatio.jpg) --></li>

<li><p><strong>centerDistanceRatio</strong></p>

<ul>
<li><strong>Description</strong>: Determines whether the distance between the centers of two boxes along the y-axis is significantly large. Raising this parameter will cause words that are not strictly aligned in a straight line to be joined into a line object.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.6f</code></li>

<li><strong>Example</strong>: If the average height of words is 20 pixels, setting <code>centerDistanceRatio</code> to 1.0 will allow words with centers up to 20 pixels apart vertically to be grouped into the same line.</li></ul>

<img alt="image" style="height:75px" src="../about/assets/centerDistanceRatio.jpg">
<!-- ![centerDistanceRatio](../about/assets/centerDistanceRatio.jpg) --></li>

<li><p><strong>paragraphHeightDistance</strong></p>

<ul>
<li><strong>Description</strong>: Determines the difference in the distance between the centers of two rows along the y-axis. Raising this parameter will cause lines that are spaced out vertically to be joined into a paragraph.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>1.0f</code></li>

<li><strong>Example</strong>: If the average height of lines is 30 pixels, setting <code>paragraphHeightDistance</code> to 2 will allow lines with centers up to 60 pixels apart vertically to be grouped into the same paragraph.</li></ul>

<img alt="image" style="height:125px" src="../about/assets/paragraphHeightDistance.jpg">
<!-- ![paragraphHeightDistance](../about/assets/paragraphHeightDistance.jpg) --></li>

<li><p><strong>paragraphHeightRatioThreshold</strong></p>

<ul>
<li><strong>Description</strong>: Determines whether there is a significant difference in the heights of two rows. Lowering this parameter will cause lines with higher difference in heights to be joined into a paragraph.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>1.0f/3.0f</code></li>

<li><strong>Example</strong>: If the average height of lines is 50 pixels, setting <code>paragraphHeightRatioThreshold</code> to 0.2 will allow lines with heights ranging from approximately 10 pixels to 250 pixels to be grouped into the same paragraph.</li></ul>

<img alt="image" style="height:125px" src="../about/assets/paragraphHeightRatioThreshold.jpg">
<!-- ![paragraphHeightRatioThreshold](../about/assets/paragraphHeightRatioThreshold.jpg) --></li></ol></li>
</ul>

<h3 id="tilingoptions" class="anchor"><a class="heading-anchor" href="#tilingoptions"><span></span></a>Tiling Options</h3>

<p><strong>tiling</strong></p>

<ul>
<li><strong>Description</strong>: A structure containing parameters related to handling very long text boxes.</li>

<li><strong>Type</strong>: <code>OpenCVOcrTiler::Options</code></li>

<li><strong>Fields</strong>:


<ol>
<li><strong>enable</strong>


<ul>
<li><strong>Description</strong>: Enable tiling of elongated text boxes. Boxes that match aspect ratio criteria will be split into multiple images (tiles) and recognition will be performed on each of them. After that, a correlation method will be used to merge the results of recognition into a single set of decodes. Enabling this option may help recognize text in long strings of characters.</li>

<li><strong>Type</strong>: <code>bool</code></li>

<li><strong>Default</strong>: <code>false</code></li></ul>
</li>

<li><strong>topCorrelationThr</strong>


<ul>
<li><strong>Description</strong>: Increasing this value will reduce the number of combinations used internally to perform tiling based on their confidence. Tuning this value may increase/decrease tiling result accuracy. Setting it to 0 will turn this feature off.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.0f</code></li>

<li><strong>Valid range</strong>: <code>[0.0f, 1.0f]</code></li></ul>
</li>

<li><strong>mergePointsCutoff</strong>


<ul>
<li><strong>Description</strong>: This is an internal parameter used to limit the number of possible combinations used for tile merging. Raising this value will result in more combinations being used internally and will increase the processing time but can also generate more accurate results.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>5</code></li></ul>
</li>

<li><strong>splitMarginFactor</strong>


<ul>
<li><strong>Description</strong>: This parameter scales the confidence values for characters that are at the borders of consecutive tiles, assuming that characters that these characters could be deformed due to cutting the image into tiles. It's not recommended to modify this value.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>0.1f</code></li>

<li><strong>Valid range</strong>: <code>[0.0f, 1.0f]</code></li></ul>
</li>

<li><strong>aspectRatioLowerThr</strong>


<ul>
<li><strong>Description</strong>: Tiling algorithm decides which boxes should be tiled and which not. Lowering this threshold will result with more boxes, with smaller aspect ratio (width/height) being tiled. Lowering this value can result in increased processing time.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>10.0f</code></li></ul>
</li>

<li><strong>aspectRatioUpperThr</strong>


<ul>
<li><strong>Description</strong>: This threshold alows filtering of boxes with very high aspect ratio. Such boxes rarely occur naturally and sometimes are a false positive of text detector model. Lowering this value will result in less boxes being tiled.</li>

<li><strong>Type</strong>: <code>float</code></li>

<li><strong>Default</strong>: <code>40.0f</code></li></ul>
</li>

<li><strong>topkMergedPredictions</strong>


<ul>
<li><strong>Description</strong>: The final tiling result - the decodes, are sorted based on their confidence score. This setting allows the user to limit the number of decodes being returned from the OCR.</li>

<li><strong>Type</strong>: <code>int</code></li>

<li><strong>Default</strong>: <code>5</code></li></ul>
</li></ol>
</li>
</ul>

<p><br></p>

<!-- TextOCR.md#textocrsettingssettings -->

<!-- 
## APIs
The following is a list of APIs supported by TextOCR.
Return Type                          |  API Name
-------------------------------------| --------------------------------------
TextOCR       | [TextOCR](TextOCR.md#textocrsettingssettings)   ([Settings](TextOCRSettings.md) settings) throws FileNotFoundException, IOException
CompletableFuture<[OCRResult](OCRResult.md)[]> | [detect](TextOCR.md#detect-bitmapsrcimg) (Bitmap srcImg) throws InvalidInputException
CompletableFuture<[Word](Word.md)[]> |    [detectWords](TextOCR.md#detectwordsbitmapsrcimg) (Bitmap srcImg) throws InvalidInputException
CompletableFuture<[TextParagraph](TextParagraph.md)[]> |    [detectParagraphs](TextOCR.md#detectparagraphs-bitmapsrcimg) (Bitmap srcImg) throws InvalidInputException
void      | [dispose](TextOCR.md#dispose-) ()
-->

<h2 id="apis" class="anchor"><a class="heading-anchor" href="#apis"><span></span></a>APIs</h2>

<p>The <code>TextOCR</code> class is part of the <code>com.zebra.AI.Vision</code> package and is used for detecting and recognizing text in images. It provides methods for detecting text at different granularities, including words and paragraphs. This class is essential for applications that require text extraction from images, such as document scanning, automated data entry, and more.</p>

<h3 id="textocrsettingssettings" class="anchor"><a class="heading-anchor" href="#textocrsettingssettings"><span></span></a>TextOCR(Settings settings)</h3>

<p>Initializes the OCR engine with the specified settings, allowing subsequent text detection and analysis on image inputs. It validates the availability of required model files and ensures the integrity of the archive. If any issues are detected, appropriate exceptions are thrown.</p>

<ul>
<li><strong>Constructor:</strong>


<ul>
<li>TextOCR.TextOCR (<a href="../textocr/textocrsettings/">Settings</a> settings) throws FileNotFoundException, IOException</li></ul>
</li>

<li><strong>Parameters:</strong>


<ul>
<li><code>settings</code> - <a href="../textocr/textocrsettings/">TextOCR.Settings settings</a> to construct an OCR object with.
An instance of the <code>Settings</code> class, containing configuration options for the OCR engine. These settings include model paths, language preferences, and performance configurations.</li></ul>
</li>

<li><strong>Exceptions:</strong>


<ul>
<li><code>FileNotFoundException</code> - Thrown if the required model file is not found in the archive.</li>

<li><code>IOException</code> - Thrown if the archive is corrupted.</li></ul>
</li>
</ul>

<h3 id="detectbitmapsrcimg" class="anchor"><a class="heading-anchor" href="#detectbitmapsrcimg"><span></span></a>detect (Bitmap srcImg)</h3>

<p>Performs Optical Character Recognition (OCR) on the provided Bitmap image.</p>

<ul>
<li><strong>Method:</strong>


<ul>
<li><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html">CompletableFuture</a>&lt;<a href="../class/ocrresult/">OCRResult</a>[ ]&gt; TextOCR.detect (Bitmap srcImg) throws <a href="../class/invalidinputexception/">InvalidInputException</a></li></ul>
</li>

<li><strong>Parameters:</strong>


<ul>
<li><code>srcImg</code> (Bitmap srcImg) - A <code>Bitmap</code> image to perform OCR detection on.</li></ul>
</li>

<li><strong>Return Value:</strong>


<ul>
<li>An array of <a href="../class/ocrresult/">OCRResult</a> containing bounding boxes and recognized text.</li></ul>
</li>

<li><strong>Exceptions:</strong>


<ul>
<li><code>InvalidInputException</code> - Thrown when Bitmap is passed as null. </li></ul>
</li>
</ul>

<h3 id="detectwordsbitmapsrcimg" class="anchor"><a class="heading-anchor" href="#detectwordsbitmapsrcimg"><span></span></a>detectWords(Bitmap    srcImg)</h3>

<p>Detects individual words in the given Bitmap image. Each word may have multiple possible readings with associated confidence scores.</p>

<ul>
<li><strong>Method:</strong> 


<ul>
<li><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html">CompletableFuture</a>&lt;<a href="../class/word/">Word</a>[ ]&gt; TextOCR.detectWords(Bitmap    srcImg) throws <a href="../class/invalidinputexception/">InvalidInputException</a></li></ul>
</li>

<li><strong>Parameters:</strong>


<ul>
<li><code>srcImg</code> (Bitmap srcImg) - The image to analyze for word detection.</li></ul>
</li>

<li><strong>Exceptions:</strong>


<ul>
<li><code>InvalidInputException</code> thrown when Bitmap is passed as null. </li></ul>
</li>

<li><strong>Return Value:</strong>


<ul>
<li>An array of <code>Words</code> objects containing bounding boxes and possible text decodes.</li></ul>
</li>
</ul>

<h3 id="detectparagraphsbitmapsrcimg" class="anchor"><a class="heading-anchor" href="#detectparagraphsbitmapsrcimg"><span></span></a>detectParagraphs (Bitmap    srcImg)</h3>

<p>Detects paragraphs in the given Bitmap image. Words are grouped into lines and paragraphs based on layout.</p>

<ul>
<li><strong>Prototype:</strong>


<ul>
<li><a href="https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html">CompletableFuture</a>&lt;<a href="../class/textparagraph/">TextParagraph</a>[ ]&gt; TextOCR.detectParagraphs (Bitmap    srcImg) throws <a href="../class/invalidinputexception/">InvalidInputException</a></li></ul>
</li>

<li><strong>Parameters:</strong>


<ul>
<li><code>srcImg</code> (Bitmap srcImg): The image to analyze for paragraph detection.</li></ul>
</li>

<li><strong>Return Value:</strong>


<ul>
<li>An array of <code>TextParagraph</code> objects representing detected paragraphs.</li></ul>
</li>

<li><strong>Exceptions:</strong> 


<ul>
<li><code>InvalidInputException</code> - Thrown when Bitmap is passed as null. </li></ul>
</li>
</ul>

<h3 id="dispose" class="anchor"><a class="heading-anchor" href="#dispose"><span></span></a>dispose ()</h3>

<p>Releases all internal resources used by the <code>TextOCR</code> object. This function needs to be called manually to free up resources.</p>

<ul>
<li><strong>Constructor:</strong>


<ul>
<li>void dispose()</li></ul>
</li>
</ul><p></p>
                                        


                                    </div>
                                </div>

                            </div>
                        </div>
                    </div>
                </div><!--/.col-sm-6-->
            </div>
            </section>
        </div>
    </section>    

<div class="modal fade" id="basicModal" tabindex="-1" role="dialog" aria-labelledby="basicModal" aria-hidden="true" data-backdrop="true">
			<div class="modal-dialog">
				<div class="modal-content">
					<div class="modal-header">
						<button type="button" class="close" data-dismiss="modal" aria-hidden="true">X</button>
					</div>
					<div class="modal-body">
						<div id="modalImg">
						
						</div>
					</div>
			</div>
		  </div>
		</div> </div>
         <footer id="footer">
            <div class="container-fluid">
                <div class="row">
                    <div class="col-sm-10">
                        ZEBRA and the stylized Zebra head are trademarks of Zebra Technologies Corp., registered in many jurisdictions worldwide. All other trademarks are the property of their respective owners. ©2025 Zebra Technologies Corp. and/or its affiliates.<br> <a href="https://www.zebra.com/us/en/about-zebra/company-information/legal.html">Legal</a> | <a href="https://www.zebra.com/us/en/about-zebra/company-information/compliance/information-privacy/terms-of-use.html">Terms of Use</a> | <a href="https://www.zebra.com/us/en/about-zebra/company-information/legal/privacy-statement.html">Privacy Policy</a> 
                    </div>
                     <!--
                     <div class="col-sm-2">
                        <ul class="social-icons">
                            <li><a href="http://www.facebook.com/pages/Zebra-Technologies/107703715989073"><i class="fa fa-facebook"></i></a></li>
                            <li><a href="https://twitter.com/ZebraDevs"><i class="fa fa-twitter"></i></a></li>
                            <li><a href="http://www.youtube.com/zebratechnologies/"><i class="fa fa-youtube"></i></a></li>
                            <li><a href="https://www.linkedin.com/groups?home=&gid=3220074&trk=anet_ug_hm&goback=%2Egmr_3220074"><i class="fa fa-linkedin"></i></a></li>
                            <li><a href="https://github.com/developer-zebra"><i class="fa fa-github"></i></a></li>
                        </ul>
                    </div> -->
                 </div>
            </div>
        </footer>
    
    <!--/#footer 
        10/25/18 removed <footer id="footer" class="navbar-fixed-bottom">
    -->
    <script src="/js/bootstrap.min.js"></script>
    <script src="/js/owl.carousel.min.js"></script>
    <script src="/js/mousescroll.js"></script>
    <script src="/js/smoothscroll.js"></script>
    <script src="/js/jquery.prettyPhoto.js"></script>
    <script src="/js/jquery.isotope.min.js"></script>
    <script src="/js/jquery.inview.min.js"></script>
    <script src="/js/wow.min.js"></script>
    <script src="/js/bootstrap-treenav.min.js"></script>
    <script src="/js/prettify.js"></script>
    <script src="/js/zepto.js"></script>
    <script src="/js/jquery.waterfall.js"></script>   
    <script src="/js/main.js"></script>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install','zRzEsAUhWTTkrdEN2YfA','2.0.0');
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-72584442-1', 'auto');
  ga('send', 'pageview');

</script> 

<script>
    ChatraID = 'QDvZ76min4DhLW5vJ';
    (function(d, w, c) {
        var n = d.getElementsByTagName('script')[0],
            s = d.createElement('script');
        w[c] = w[c] || function() {
            (w[c].q = w[c].q || []).push(arguments);
        };
        s.async = true;
        s.src = (d.location.protocol === 'https:' ? 'https:': 'http:')
            + '//call.chatra.io/chatra.js';
        n.parentNode.insertBefore(s, n);
    })(document, window, 'Chatra');
</script>         


</body></html>